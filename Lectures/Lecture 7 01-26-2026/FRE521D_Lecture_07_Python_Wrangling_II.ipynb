{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRE 521D: Data Analytics in Climate, Food and Environment\n",
    "## Lecture 6: Python Wrangling II - Merges, Reshaping, and Analysis-Ready Tables\n",
    "\n",
    "**Date:** Monday, January 26, 2026  \n",
    "**Instructor:** Asif Ahmed Neloy  \n",
    "**Program:** UBC Master of Food and Resource Economics\n",
    "\n",
    "---\n",
    "\n",
    "### Today's Agenda\n",
    "\n",
    "1. Quick Review: Tidy Data Principles\n",
    "2. Merging Multiple Data Sources\n",
    "3. Advanced Pivot and Unpivot Patterns\n",
    "4. Building Analysis-Ready Tables\n",
    "5. Data Contracts and Documentation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "Ready for Python Wrangling II!\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Ready for Python Wrangling II!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Quick Review: Tidy Data\n",
    "\n",
    "From last class:\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────┐\n",
    "│           TIDY DATA PRINCIPLES                 │\n",
    "├────────────────────────────────────────────────┤\n",
    "│  1. Each VARIABLE → its own COLUMN            │\n",
    "│  2. Each OBSERVATION → its own ROW            │\n",
    "│  3. Each VALUE → its own CELL                 │\n",
    "└────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "Today we focus on **combining multiple tidy datasets** into analysis-ready tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Merging Multiple Data Sources\n",
    "\n",
    "### The Real-World Scenario\n",
    "\n",
    "In climate and food analytics, data comes from many sources:\n",
    "- Country metadata (World Bank)\n",
    "- Economic indicators (GDP, trade)\n",
    "- Climate data (temperature, precipitation)\n",
    "- Agricultural production (FAO)\n",
    "- Environmental metrics (emissions, land use)\n",
    "\n",
    "You need to combine them for integrated analysis.\n",
    "\n",
    "### Types of Joins\n",
    "\n",
    "```\n",
    "LEFT JOIN                INNER JOIN               OUTER JOIN\n",
    "┌─────┬─────┐           ┌─────┬─────┐           ┌─────┬─────┐\n",
    "│█████│     │           │     │     │           │█████│█████│\n",
    "│█████│█████│           │     │█████│           │█████│█████│\n",
    "│█████│     │           │     │     │           │█████│█████│\n",
    "└─────┴─────┘           └─────┴─────┘           └─────┴─────┘\n",
    " All left +              Only matching           All from both\n",
    " matching right\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries (12 rows):\n",
      "   country_code    country_name         region         income_group\n",
      "0           CAN          Canada  North America          High income\n",
      "1           USA   United States  North America          High income\n",
      "2           MEX          Mexico  North America  Upper middle income\n",
      "3           BRA          Brazil  South America  Upper middle income\n",
      "4           ARG       Argentina  South America  Upper middle income\n",
      "5           DEU         Germany         Europe          High income\n",
      "6           FRA          France         Europe          High income\n",
      "7           GBR  United Kingdom         Europe          High income\n",
      "8           CHN           China           Asia  Upper middle income\n",
      "9           IND           India           Asia  Lower middle income\n",
      "10          JPN           Japan           Asia          High income\n",
      "11          AUS       Australia        Oceania          High income\n"
     ]
    }
   ],
   "source": [
    "# Create realistic datasets for merging\n",
    "\n",
    "# Dataset 1: Country metadata\n",
    "countries = pd.DataFrame({\n",
    "    'country_code': ['CAN', 'USA', 'MEX', 'BRA', 'ARG', 'DEU', 'FRA', 'GBR', 'CHN', 'IND', 'JPN', 'AUS'],\n",
    "    'country_name': ['Canada', 'United States', 'Mexico', 'Brazil', 'Argentina', 'Germany', \n",
    "                     'France', 'United Kingdom', 'China', 'India', 'Japan', 'Australia'],\n",
    "    'region': ['North America', 'North America', 'North America', 'South America', 'South America',\n",
    "               'Europe', 'Europe', 'Europe', 'Asia', 'Asia', 'Asia', 'Oceania'],\n",
    "    'income_group': ['High income', 'High income', 'Upper middle income', 'Upper middle income',\n",
    "                     'Upper middle income', 'High income', 'High income', 'High income',\n",
    "                     'Upper middle income', 'Lower middle income', 'High income', 'High income']\n",
    "})\n",
    "\n",
    "print(\"Countries (12 rows):\")\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GDP Data (10 rows - missing ARG, AUS):\n",
      "  iso3  year  gdp_billion_usd\n",
      "0  CAN  2022             2140\n",
      "1  USA  2022            25460\n",
      "2  MEX  2022             1414\n",
      "3  BRA  2022             1920\n",
      "4  DEU  2022             4072\n",
      "5  FRA  2022             2780\n",
      "6  GBR  2022             3070\n",
      "7  CHN  2022            17963\n",
      "8  IND  2022             3385\n",
      "9  JPN  2022             4231\n"
     ]
    }
   ],
   "source": [
    "# Dataset 2: GDP data (some countries missing)\n",
    "gdp_data = pd.DataFrame({\n",
    "    'iso3': ['CAN', 'USA', 'MEX', 'BRA', 'DEU', 'FRA', 'GBR', 'CHN', 'IND', 'JPN'],  # Missing ARG, AUS\n",
    "    'year': [2022] * 10,\n",
    "    'gdp_billion_usd': [2140, 25460, 1414, 1920, 4072, 2780, 3070, 17963, 3385, 4231]\n",
    "})\n",
    "\n",
    "print(\"\\nGDP Data (10 rows - missing ARG, AUS):\")\n",
    "print(gdp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CO2 Emissions (14 rows - includes extra RUS, KOR):\n",
      "   country_iso  year  co2_mt\n",
      "0          CAN  2022     565\n",
      "1          USA  2022    5007\n",
      "2          MEX  2022     477\n",
      "3          BRA  2022     478\n",
      "4          ARG  2022     185\n",
      "5          DEU  2022     675\n",
      "6          FRA  2022     306\n",
      "7          GBR  2022     341\n",
      "8          CHN  2022   11472\n",
      "9          IND  2022    2693\n",
      "10         JPN  2022    1081\n",
      "11         AUS  2022     394\n",
      "12         RUS  2022    1756\n",
      "13         KOR  2022     616\n"
     ]
    }
   ],
   "source": [
    "# Dataset 3: CO2 emissions (some extra countries)\n",
    "emissions = pd.DataFrame({\n",
    "    'country_iso': ['CAN', 'USA', 'MEX', 'BRA', 'ARG', 'DEU', 'FRA', 'GBR', 'CHN', 'IND', 'JPN', 'AUS',\n",
    "                    'RUS', 'KOR'],  # Extra: RUS, KOR\n",
    "    'year': [2022] * 14,\n",
    "    'co2_mt': [565, 5007, 477, 478, 185, 675, 306, 341, 11472, 2693, 1081, 394, 1756, 616]\n",
    "})\n",
    "\n",
    "print(\"\\nCO2 Emissions (14 rows - includes extra RUS, KOR):\")\n",
    "print(emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agricultural Production (10 rows):\n",
      "  code  year  wheat_prod_mt  maize_prod_mt\n",
      "0  CAN  2022           34.0           14.5\n",
      "1  USA  2022           44.9          348.8\n",
      "2  MEX  2022            3.2           27.5\n",
      "3  BRA  2022           10.5          113.0\n",
      "4  ARG  2022           23.0           52.0\n",
      "5  DEU  2022           22.1            3.8\n",
      "6  FRA  2022           33.7           11.5\n",
      "7  CHN  2022          138.0          277.0\n",
      "8  IND  2022          107.7           33.6\n",
      "9  AUS  2022           36.0            0.5\n"
     ]
    }
   ],
   "source": [
    "# Dataset 4: Agricultural production\n",
    "ag_production = pd.DataFrame({\n",
    "    'code': ['CAN', 'USA', 'MEX', 'BRA', 'ARG', 'DEU', 'FRA', 'CHN', 'IND', 'AUS'],\n",
    "    'year': [2022] * 10,\n",
    "    'wheat_prod_mt': [34.0, 44.9, 3.2, 10.5, 23.0, 22.1, 33.7, 138.0, 107.7, 36.0],\n",
    "    'maize_prod_mt': [14.5, 348.8, 27.5, 113.0, 52.0, 3.8, 11.5, 277.0, 33.6, 0.5]\n",
    "})\n",
    "\n",
    "print(\"\\nAgricultural Production (10 rows):\")\n",
    "print(ag_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Challenge: Different Column Names for Keys\n",
    "\n",
    "Notice that the country code column has different names:\n",
    "- `country_code` in countries\n",
    "- `iso3` in GDP\n",
    "- `country_iso` in emissions\n",
    "- `code` in agriculture\n",
    "\n",
    "This is extremely common in real data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: LEFT JOIN with different key names\n",
      "Result shape: (12, 7)\n",
      "  country_code   country_name iso3  gdp_billion_usd\n",
      "0          CAN         Canada  CAN           2140.0\n",
      "1          USA  United States  USA          25460.0\n",
      "2          MEX         Mexico  MEX           1414.0\n",
      "3          BRA         Brazil  BRA           1920.0\n",
      "4          ARG      Argentina  NaN              NaN\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Using left_on and right_on parameters\n",
    "\n",
    "merged_1 = pd.merge(\n",
    "    countries,\n",
    "    gdp_data,\n",
    "    left_on='country_code',   # Key column in left DataFrame\n",
    "    right_on='iso3',          # Key column in right DataFrame\n",
    "    how='left'                # Keep all countries\n",
    ")\n",
    "\n",
    "print(\"Method 1: LEFT JOIN with different key names\")\n",
    "print(f\"Result shape: {merged_1.shape}\")\n",
    "print(merged_1[['country_code', 'country_name', 'iso3', 'gdp_billion_usd']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping redundant column:\n",
      "['country_code', 'country_name', 'region', 'income_group', 'year', 'gdp_billion_usd']\n"
     ]
    }
   ],
   "source": [
    "# Notice we have both country_code AND iso3 columns\n",
    "# This is redundant - let's clean it up\n",
    "\n",
    "merged_1 = merged_1.drop(columns=['iso3'])\n",
    "print(\"After dropping redundant column:\")\n",
    "print(merged_1.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed DataFrames now all have 'country_code':\n",
      "  GDP columns: ['country_code', 'year', 'gdp_billion_usd']\n",
      "  Emissions columns: ['country_code', 'year', 'co2_mt']\n",
      "  Agriculture columns: ['country_code', 'year', 'wheat_prod_mt', 'maize_prod_mt']\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Rename columns first for cleaner joins\n",
    "\n",
    "# Standardize key column names before merging\n",
    "gdp_renamed = gdp_data.rename(columns={'iso3': 'country_code'})\n",
    "emissions_renamed = emissions.rename(columns={'country_iso': 'country_code'})\n",
    "ag_renamed = ag_production.rename(columns={'code': 'country_code'})\n",
    "\n",
    "print(\"Renamed DataFrames now all have 'country_code':\")\n",
    "print(f\"  GDP columns: {gdp_renamed.columns.tolist()}\")\n",
    "print(f\"  Emissions columns: {emissions_renamed.columns.tolist()}\")\n",
    "print(f\"  Agriculture columns: {ag_renamed.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2: Merge after renaming\n",
      "  country_code   country_name  gdp_billion_usd\n",
      "0          CAN         Canada           2140.0\n",
      "1          USA  United States          25460.0\n",
      "2          MEX         Mexico           1414.0\n",
      "3          BRA         Brazil           1920.0\n",
      "4          ARG      Argentina              NaN\n"
     ]
    }
   ],
   "source": [
    "# Now merge becomes cleaner\n",
    "\n",
    "merged_2 = pd.merge(\n",
    "    countries,\n",
    "    gdp_renamed,\n",
    "    on='country_code',   # Same column name in both\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Method 2: Merge after renaming\")\n",
    "print(merged_2[['country_code', 'country_name', 'gdp_billion_usd']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining Multiple Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset (all sources):\n",
      "   country_code    country_name         region         income_group    year  \\\n",
      "0           CAN          Canada  North America          High income  2022.0   \n",
      "1           USA   United States  North America          High income  2022.0   \n",
      "2           MEX          Mexico  North America  Upper middle income  2022.0   \n",
      "3           BRA          Brazil  South America  Upper middle income  2022.0   \n",
      "4           ARG       Argentina  South America  Upper middle income     NaN   \n",
      "5           DEU         Germany         Europe          High income  2022.0   \n",
      "6           FRA          France         Europe          High income  2022.0   \n",
      "7           GBR  United Kingdom         Europe          High income  2022.0   \n",
      "8           CHN           China           Asia  Upper middle income  2022.0   \n",
      "9           IND           India           Asia  Lower middle income  2022.0   \n",
      "10          JPN           Japan           Asia          High income  2022.0   \n",
      "11          AUS       Australia        Oceania          High income     NaN   \n",
      "\n",
      "    gdp_billion_usd  co2_mt  wheat_prod_mt  maize_prod_mt  \n",
      "0            2140.0     565           34.0           14.5  \n",
      "1           25460.0    5007           44.9          348.8  \n",
      "2            1414.0     477            3.2           27.5  \n",
      "3            1920.0     478           10.5          113.0  \n",
      "4               NaN     185           23.0           52.0  \n",
      "5            4072.0     675           22.1            3.8  \n",
      "6            2780.0     306           33.7           11.5  \n",
      "7            3070.0     341            NaN            NaN  \n",
      "8           17963.0   11472          138.0          277.0  \n",
      "9            3385.0    2693          107.7           33.6  \n",
      "10           4231.0    1081            NaN            NaN  \n",
      "11              NaN     394           36.0            0.5  \n"
     ]
    }
   ],
   "source": [
    "# Chain multiple merges to combine all datasets\n",
    "\n",
    "combined = (\n",
    "    countries\n",
    "    .merge(gdp_renamed, on='country_code', how='left')\n",
    "    .merge(emissions_renamed[['country_code', 'co2_mt']], on='country_code', how='left')\n",
    "    .merge(ag_renamed[['country_code', 'wheat_prod_mt', 'maize_prod_mt']], on='country_code', how='left')\n",
    ")\n",
    "\n",
    "print(\"Combined dataset (all sources):\")\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after merge:\n",
      "country_code       0\n",
      "country_name       0\n",
      "region             0\n",
      "income_group       0\n",
      "year               2\n",
      "gdp_billion_usd    2\n",
      "co2_mt             0\n",
      "wheat_prod_mt      2\n",
      "maize_prod_mt      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check what's missing\n",
    "print(\"\\nMissing values after merge:\")\n",
    "print(combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Types in Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT JOIN:  12 rows (keeps all 12 countries)\n",
      "INNER JOIN: 10 rows (only countries with GDP data)\n",
      "OUTER JOIN: 14 rows (all countries + extra from emissions)\n"
     ]
    }
   ],
   "source": [
    "# Compare different join types\n",
    "\n",
    "# LEFT JOIN: All from left, matching from right\n",
    "left_result = countries.merge(gdp_renamed, on='country_code', how='left')\n",
    "print(f\"LEFT JOIN:  {len(left_result)} rows (keeps all {len(countries)} countries)\")\n",
    "\n",
    "# INNER JOIN: Only matching rows\n",
    "inner_result = countries.merge(gdp_renamed, on='country_code', how='inner')\n",
    "print(f\"INNER JOIN: {len(inner_result)} rows (only countries with GDP data)\")\n",
    "\n",
    "# OUTER JOIN: All rows from both\n",
    "outer_result = countries.merge(emissions_renamed, on='country_code', how='outer')\n",
    "print(f\"OUTER JOIN: {len(outer_result)} rows (all countries + extra from emissions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer join includes extra countries from emissions:\n",
      "   country_code country_name  co2_mt\n",
      "10          KOR          NaN     616\n",
      "12          RUS          NaN    1756\n"
     ]
    }
   ],
   "source": [
    "# See what the outer join added\n",
    "print(\"\\nOuter join includes extra countries from emissions:\")\n",
    "extra_rows = outer_result[outer_result['country_name'].isnull()]\n",
    "print(extra_rows[['country_code', 'country_name', 'co2_mt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicate Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge with duplicate 'year' column:\n",
      "  country_code  year_x    gdp  year_y  population\n",
      "0          CAN    2022   2140    2022          38\n",
      "1          USA    2022  25460    2022         331\n",
      "2          MEX    2022   1414    2022         128\n"
     ]
    }
   ],
   "source": [
    "# When both DataFrames have the same non-key column\n",
    "\n",
    "# Create two datasets with 'year' column\n",
    "df1 = pd.DataFrame({\n",
    "    'country_code': ['CAN', 'USA', 'MEX'],\n",
    "    'year': [2022, 2022, 2022],\n",
    "    'gdp': [2140, 25460, 1414]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'country_code': ['CAN', 'USA', 'MEX'],\n",
    "    'year': [2022, 2022, 2022],\n",
    "    'population': [38, 331, 128]\n",
    "})\n",
    "\n",
    "# Merge creates suffixes\n",
    "merged_suffix = df1.merge(df2, on='country_code')\n",
    "print(\"Merge with duplicate 'year' column:\")\n",
    "print(merged_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1 - Merge on both keys:\n",
      "  country_code  year    gdp  population\n",
      "0          CAN  2022   2140          38\n",
      "1          USA  2022  25460         331\n",
      "2          MEX  2022   1414         128\n",
      "\n",
      "Option 2 - Custom suffixes:\n",
      "  country_code  year_gdp    gdp  year_pop  population\n",
      "0          CAN      2022   2140      2022          38\n",
      "1          USA      2022  25460      2022         331\n",
      "2          MEX      2022   1414      2022         128\n"
     ]
    }
   ],
   "source": [
    "# Better: Include 'year' in the key or use custom suffixes\n",
    "\n",
    "# Option 1: Merge on both columns\n",
    "merged_both_keys = df1.merge(df2, on=['country_code', 'year'])\n",
    "print(\"Option 1 - Merge on both keys:\")\n",
    "print(merged_both_keys)\n",
    "\n",
    "# Option 2: Custom suffixes\n",
    "merged_custom = df1.merge(df2, on='country_code', suffixes=('_gdp', '_pop'))\n",
    "print(\"\\nOption 2 - Custom suffixes:\")\n",
    "print(merged_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation caught the problem: MergeError\n",
      "Message: Merge keys are not unique in right dataset; not a one-to-one merge\n"
     ]
    }
   ],
   "source": [
    "# The 'validate' parameter catches merge problems\n",
    "\n",
    "# Create a dataset with duplicates\n",
    "df_with_dups = pd.DataFrame({\n",
    "    'country_code': ['CAN', 'CAN', 'USA'],  # CAN appears twice!\n",
    "    'metric': ['a', 'b', 'c']\n",
    "})\n",
    "\n",
    "try:\n",
    "    # This will fail because df_with_dups has duplicate keys\n",
    "    result = countries.merge(\n",
    "        df_with_dups,\n",
    "        on='country_code',\n",
    "        how='left',\n",
    "        validate='one_to_one'  # Expect each key appears once in both\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Validation caught the problem: {type(e).__name__}\")\n",
    "    print(f\"Message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated merge successful!\n"
     ]
    }
   ],
   "source": [
    "# Validate options:\n",
    "# - \"one_to_one\" or \"1:1\": Both sides have unique keys\n",
    "# - \"one_to_many\" or \"1:m\": Left side has unique keys\n",
    "# - \"many_to_one\" or \"m:1\": Right side has unique keys\n",
    "# - \"many_to_many\" or \"m:m\": No uniqueness requirements (careful!)\n",
    "\n",
    "# Correct usage for our data\n",
    "result = countries.merge(\n",
    "    gdp_renamed,\n",
    "    on='country_code',\n",
    "    how='left',\n",
    "    validate='one_to_one'  # Both have unique country codes\n",
    ")\n",
    "print(\"Validated merge successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Advanced Pivot and Unpivot Patterns\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "| Pattern | Function | Use Case |\n",
    "|---------|----------|----------|\n",
    "| Unpivot (wide→long) | `pd.melt()` | Column headers are data values |\n",
    "| Pivot (long→wide) | `df.pivot()` | Need to spread values across columns |\n",
    "| Pivot with aggregation | `df.pivot_table()` | Need to aggregate when pivoting |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Prices (wide format):\n",
      "         date  wheat_usd_ton  maize_usd_ton  soybeans_usd_ton  rice_usd_ton\n",
      "0  2023-01-31            315            285               520           425\n",
      "1  2023-02-28            320            290               535           430\n",
      "2  2023-03-31            310            288               528           428\n",
      "3  2023-04-30            305            280               515           432\n",
      "4  2023-05-31            298            275               502           438\n",
      "5  2023-06-30            285            268               495           445\n",
      "6  2023-07-31            280            265               488           452\n",
      "7  2023-08-31            290            272               498           458\n",
      "8  2023-09-30            295            278               510           462\n",
      "9  2023-10-31            288            275               505           455\n",
      "10 2023-11-30            282            270               495           448\n",
      "11 2023-12-31            278            268               490           445\n"
     ]
    }
   ],
   "source": [
    "# Create commodity price data (realistic format from data providers)\n",
    "\n",
    "commodity_prices = pd.DataFrame({\n",
    "    'date': pd.date_range('2023-01-01', periods=12, freq='M'),\n",
    "    'wheat_usd_ton': [315, 320, 310, 305, 298, 285, 280, 290, 295, 288, 282, 278],\n",
    "    'maize_usd_ton': [285, 290, 288, 280, 275, 268, 265, 272, 278, 275, 270, 268],\n",
    "    'soybeans_usd_ton': [520, 535, 528, 515, 502, 495, 488, 498, 510, 505, 495, 490],\n",
    "    'rice_usd_ton': [425, 430, 428, 432, 438, 445, 452, 458, 462, 455, 448, 445]\n",
    "})\n",
    "\n",
    "print(\"Commodity Prices (wide format):\")\n",
    "print(commodity_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidy format (long):\n",
      "         date commodity  price_usd_ton\n",
      "0  2023-01-31     wheat            315\n",
      "1  2023-02-28     wheat            320\n",
      "2  2023-03-31     wheat            310\n",
      "3  2023-04-30     wheat            305\n",
      "4  2023-05-31     wheat            298\n",
      "5  2023-06-30     wheat            285\n",
      "6  2023-07-31     wheat            280\n",
      "7  2023-08-31     wheat            290\n",
      "8  2023-09-30     wheat            295\n",
      "9  2023-10-31     wheat            288\n",
      "10 2023-11-30     wheat            282\n",
      "11 2023-12-31     wheat            278\n",
      "\n",
      "Shape: (48, 3)\n"
     ]
    }
   ],
   "source": [
    "# Unpivot: Make this tidy for analysis\n",
    "\n",
    "prices_long = pd.melt(\n",
    "    commodity_prices,\n",
    "    id_vars=['date'],\n",
    "    value_vars=['wheat_usd_ton', 'maize_usd_ton', 'soybeans_usd_ton', 'rice_usd_ton'],\n",
    "    var_name='commodity',\n",
    "    value_name='price_usd_ton'\n",
    ")\n",
    "\n",
    "# Clean up commodity names\n",
    "prices_long['commodity'] = prices_long['commodity'].str.replace('_usd_ton', '')\n",
    "\n",
    "print(\"Tidy format (long):\")\n",
    "print(prices_long.head(12))\n",
    "print(f\"\\nShape: {prices_long.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average price by commodity:\n",
      "            mean  min  max\n",
      "commodity                 \n",
      "maize      276.0  265  290\n",
      "rice       443.0  425  462\n",
      "soybeans   507.0  488  535\n",
      "wheat      296.0  278  320\n",
      "\n",
      "Price change (first vs last month):\n",
      "commodity\n",
      "maize      -17\n",
      "rice        20\n",
      "soybeans   -30\n",
      "wheat      -37\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now analysis is easy!\n",
    "\n",
    "# Average price by commodity\n",
    "print(\"Average price by commodity:\")\n",
    "print(prices_long.groupby('commodity')['price_usd_ton'].agg(['mean', 'min', 'max']).round(0))\n",
    "\n",
    "# Price trend over time\n",
    "print(\"\\nPrice change (first vs last month):\")\n",
    "price_change = prices_long.groupby('commodity').apply(\n",
    "    lambda x: x.iloc[-1]['price_usd_ton'] - x.iloc[0]['price_usd_ton']\n",
    ")\n",
    "print(price_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot with Aggregation: pivot_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production data (long format):\n",
      "   country  year quarter   crop  production_mt\n",
      "0   Canada  2021      Q1  wheat           21.9\n",
      "1   Canada  2021      Q2  wheat           47.8\n",
      "2   Canada  2021      Q3  wheat           37.9\n",
      "3   Canada  2021      Q4  wheat           31.9\n",
      "4   Canada  2022      Q1  wheat           12.0\n",
      "5   Canada  2022      Q2  wheat           12.0\n",
      "6   Canada  2022      Q3  maize            7.6\n",
      "7   Canada  2022      Q4  maize           44.0\n",
      "8   Canada  2023      Q1  maize           32.1\n",
      "9   Canada  2023      Q2  maize           36.9\n",
      "10  Canada  2023      Q3  maize            5.9\n",
      "11  Canada  2023      Q4  maize           48.6\n",
      "12     USA  2021      Q1  wheat           42.5\n",
      "13     USA  2021      Q2  wheat           14.6\n",
      "14     USA  2021      Q3  wheat           13.2\n",
      "15     USA  2021      Q4  wheat           13.3\n",
      "\n",
      "Shape: (48, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create multi-country, multi-year production data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "production_data = pd.DataFrame({\n",
    "    'country': np.repeat(['Canada', 'USA', 'Brazil', 'Argentina'], 12),\n",
    "    'year': np.tile(np.repeat([2021, 2022, 2023], 4), 4),\n",
    "    'quarter': np.tile(['Q1', 'Q2', 'Q3', 'Q4'], 12),\n",
    "    'crop': np.tile(np.repeat(['wheat', 'maize'], 6), 4),\n",
    "    'production_mt': np.random.uniform(5, 50, 48).round(1)\n",
    "})\n",
    "\n",
    "print(\"Production data (long format):\")\n",
    "print(production_data.head(16))\n",
    "print(f\"\\nShape: {production_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot table: Total production by country and crop\n",
      "crop       maize  wheat\n",
      "country                \n",
      "Argentina  151.2  126.5\n",
      "Brazil     190.5  146.7\n",
      "Canada     175.1  163.5\n",
      "USA        125.9  130.9\n"
     ]
    }
   ],
   "source": [
    "# pivot_table: Create summary by country and crop\n",
    "\n",
    "summary_table = production_data.pivot_table(\n",
    "    values='production_mt',\n",
    "    index='country',          # Rows\n",
    "    columns='crop',           # Columns\n",
    "    aggfunc='sum'             # How to aggregate\n",
    ")\n",
    "\n",
    "print(\"Pivot table: Total production by country and crop\")\n",
    "print(summary_table.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex pivot with multiple aggregations:\n",
      "             sum         mean       count      \n",
      "crop       maize  wheat maize wheat maize wheat\n",
      "country                                        \n",
      "Argentina  151.2  126.5  25.2  21.1     6     6\n",
      "Brazil     190.5  146.7  31.8  24.4     6     6\n",
      "Canada     175.1  163.5  29.2  27.2     6     6\n",
      "USA        125.9  130.9  21.0  21.8     6     6\n"
     ]
    }
   ],
   "source": [
    "# More complex pivot: Multiple aggregations\n",
    "\n",
    "complex_pivot = production_data.pivot_table(\n",
    "    values='production_mt',\n",
    "    index='country',\n",
    "    columns='crop',\n",
    "    aggfunc=['sum', 'mean', 'count']  # Multiple aggregations\n",
    ")\n",
    "\n",
    "print(\"Complex pivot with multiple aggregations:\")\n",
    "print(complex_pivot.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot with country and year as rows:\n",
      "crop            maize  wheat\n",
      "country   year              \n",
      "Argentina 2021    NaN   88.7\n",
      "          2022   52.4   37.8\n",
      "          2023   98.8    NaN\n",
      "Brazil    2021    NaN  107.9\n",
      "          2022   45.0   38.8\n",
      "          2023  145.5    NaN\n",
      "Canada    2021    NaN  139.5\n",
      "          2022   51.6   24.0\n",
      "          2023  123.5    NaN\n",
      "USA       2021    NaN   83.6\n",
      "          2022   42.5   47.3\n",
      "          2023   83.4    NaN\n"
     ]
    }
   ],
   "source": [
    "# Pivot with multiple row indices\n",
    "\n",
    "yearly_summary = production_data.pivot_table(\n",
    "    values='production_mt',\n",
    "    index=['country', 'year'],  # Multiple row indices\n",
    "    columns='crop',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "print(\"Pivot with country and year as rows:\")\n",
    "print(yearly_summary.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot with country and year as rows:\n",
      "crop            maize  wheat\n",
      "country   year              \n",
      "Argentina 2021    NaN   88.7\n",
      "          2022   52.4   37.8\n",
      "          2023   98.8    NaN\n",
      "Brazil    2021    NaN  107.9\n",
      "          2022   45.0   38.8\n",
      "          2023  145.5    NaN\n",
      "Canada    2021    NaN  139.5\n",
      "          2022   51.6   24.0\n",
      "          2023  123.5    NaN\n",
      "USA       2021    NaN   83.6\n",
      "          2022   42.5   47.3\n",
      "          2023   83.4    NaN\n"
     ]
    }
   ],
   "source": [
    "# Pivot with multiple row indices\n",
    "\n",
    "yearly_summary = production_data.pivot_table(\n",
    "    values='production_mt',\n",
    "    index=['country', 'year'],  # Multiple row indices\n",
    "    columns='crop',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "print(\"Pivot with country and year as rows:\")\n",
    "print(yearly_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot with totals:\n",
      "crop       maize  wheat   Total\n",
      "country                        \n",
      "Argentina  151.2  126.5   277.7\n",
      "Brazil     190.5  146.7   337.2\n",
      "Canada     175.1  163.5   338.6\n",
      "USA        125.9  130.9   256.8\n",
      "Total      642.7  567.6  1210.3\n"
     ]
    }
   ],
   "source": [
    "# Add margins (totals)\n",
    "\n",
    "with_totals = production_data.pivot_table(\n",
    "    values='production_mt',\n",
    "    index='country',\n",
    "    columns='crop',\n",
    "    aggfunc='sum',\n",
    "    margins=True,              # Add totals\n",
    "    margins_name='Total'       # Name for total row/column\n",
    ")\n",
    "\n",
    "print(\"Pivot with totals:\")\n",
    "print(with_totals.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack and Unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original pivot table:\n",
      "crop            maize  wheat\n",
      "country   year              \n",
      "Argentina 2021    NaN   88.7\n",
      "          2022   52.4   37.8\n",
      "          2023   98.8    NaN\n",
      "Brazil    2021    NaN  107.9\n",
      "          2022   45.0   38.8\n",
      "          2023  145.5    NaN\n",
      "Canada    2021    NaN  139.5\n",
      "          2022   51.6   24.0\n",
      "\n",
      "After stack():\n",
      "country    year  crop \n",
      "Argentina  2021  wheat     88.7\n",
      "           2022  maize     52.4\n",
      "                 wheat     37.8\n",
      "           2023  maize     98.8\n",
      "Brazil     2021  wheat    107.9\n",
      "           2022  maize     45.0\n",
      "                 wheat     38.8\n",
      "           2023  maize    145.5\n",
      "Canada     2021  wheat    139.5\n",
      "           2022  maize     51.6\n",
      "                 wheat     24.0\n",
      "           2023  maize    123.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Stack: Move column index to row index\n",
    "# Unstack: Move row index to column index\n",
    "\n",
    "# Start with the pivot table\n",
    "print(\"Original pivot table:\")\n",
    "print(yearly_summary.head(8))\n",
    "\n",
    "# Stack: Make it longer\n",
    "stacked = yearly_summary.stack()\n",
    "print(\"\\nAfter stack():\")\n",
    "print(stacked.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstacked by year:\n",
      "year              2021  2022   2023\n",
      "country   crop                     \n",
      "Argentina maize    NaN  52.4   98.8\n",
      "          wheat   88.7  37.8    NaN\n",
      "Brazil    maize    NaN  45.0  145.5\n",
      "          wheat  107.9  38.8    NaN\n",
      "Canada    maize    NaN  51.6  123.5\n",
      "          wheat  139.5  24.0    NaN\n",
      "USA       maize    NaN  42.5   83.4\n",
      "          wheat   83.6  47.3    NaN\n"
     ]
    }
   ],
   "source": [
    "# Unstack: Spread a level to columns\n",
    "\n",
    "unstacked = stacked.unstack(level='year')  # Move 'year' to columns\n",
    "print(\"Unstacked by year:\")\n",
    "print(unstacked.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Building Analysis-Ready Tables\n",
    "\n",
    "### What Makes a Table \"Analysis-Ready\"?\n",
    "\n",
    "1. **Tidy structure**: Each row is one observation\n",
    "2. **Correct types**: Numeric columns are numeric, dates are datetime\n",
    "3. **Consistent keys**: Can be joined with other tables\n",
    "4. **Documented nulls**: Missing values are understood\n",
    "5. **Derived metrics**: Common calculations pre-computed\n",
    "6. **Clear naming**: Column names are descriptive\n",
    "\n",
    "### Complete Example: Climate-Agriculture Analysis Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries metadata:\n",
      "  country_code   country_name         region hemisphere  arable_land_mha\n",
      "0          CAN         Canada  North America   Northern             38.6\n",
      "1          USA  United States  North America   Northern            157.7\n",
      "2          MEX         Mexico  North America   Northern             23.3\n",
      "3          BRA         Brazil  South America   Southern             55.8\n",
      "4          ARG      Argentina  South America   Southern             39.2\n",
      "5          DEU        Germany         Europe   Northern             11.8\n",
      "6          FRA         France         Europe   Northern             18.5\n",
      "7          AUS      Australia        Oceania   Southern             31.2\n",
      "8          CHN          China           Asia   Northern            119.5\n",
      "9          IND          India           Asia   Northern            156.1\n"
     ]
    }
   ],
   "source": [
    "# Create source datasets\n",
    "\n",
    "# 1. Country metadata\n",
    "countries_meta = pd.DataFrame({\n",
    "    'country_code': ['CAN', 'USA', 'MEX', 'BRA', 'ARG', 'DEU', 'FRA', 'AUS', 'CHN', 'IND'],\n",
    "    'country_name': ['Canada', 'United States', 'Mexico', 'Brazil', 'Argentina',\n",
    "                     'Germany', 'France', 'Australia', 'China', 'India'],\n",
    "    'region': ['North America', 'North America', 'North America', 'South America',\n",
    "               'South America', 'Europe', 'Europe', 'Oceania', 'Asia', 'Asia'],\n",
    "    'hemisphere': ['Northern', 'Northern', 'Northern', 'Southern', 'Southern',\n",
    "                   'Northern', 'Northern', 'Southern', 'Northern', 'Northern'],\n",
    "    'arable_land_mha': [38.6, 157.7, 23.3, 55.8, 39.2, 11.8, 18.5, 31.2, 119.5, 156.1]\n",
    "})\n",
    "\n",
    "print(\"Countries metadata:\")\n",
    "print(countries_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crop production:\n",
      "   country_code  year  wheat_prod_mt  maize_prod_mt  yield_wheat_ton_ha  \\\n",
      "0           CAN  2020           55.6           44.5                4.23   \n",
      "1           CAN  2021          133.3          174.3                3.75   \n",
      "2           CAN  2022          103.8           14.0                3.16   \n",
      "3           CAN  2023           85.8          318.4                2.63   \n",
      "4           USA  2020           26.1           92.1                3.12   \n",
      "5           USA  2021           26.1          232.6                3.15   \n",
      "6           USA  2022           12.8          110.5                3.96   \n",
      "7           USA  2023          121.9          183.0                3.78   \n",
      "8           MEX  2020           86.2          192.3                4.27   \n",
      "9           MEX  2021          100.6           66.3                3.44   \n",
      "10          MEX  2022            7.8          339.4                2.74   \n",
      "11          MEX  2023          135.9          271.7                3.93   \n",
      "\n",
      "    yield_maize_ton_ha  \n",
      "0                10.27  \n",
      "1                11.06  \n",
      "2                 5.86  \n",
      "3                 3.99  \n",
      "4                 5.05  \n",
      "5                 6.84  \n",
      "6                10.36  \n",
      "7                10.75  \n",
      "8                 3.06  \n",
      "9                 7.60  \n",
      "10                6.76  \n",
      "11                5.00  \n"
     ]
    }
   ],
   "source": [
    "# 2. Crop production (multiple years)\n",
    "years = [2020, 2021, 2022, 2023]\n",
    "country_codes = ['CAN', 'USA', 'MEX', 'BRA', 'ARG', 'DEU', 'FRA', 'AUS', 'CHN', 'IND']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "crop_prod = pd.DataFrame({\n",
    "    'country_code': np.repeat(country_codes, len(years)),\n",
    "    'year': np.tile(years, len(country_codes)),\n",
    "    'wheat_prod_mt': np.random.uniform(5, 140, 40).round(1),\n",
    "    'maize_prod_mt': np.random.uniform(2, 350, 40).round(1),\n",
    "    'yield_wheat_ton_ha': np.random.uniform(2.5, 4.5, 40).round(2),\n",
    "    'yield_maize_ton_ha': np.random.uniform(3.0, 12.0, 40).round(2)\n",
    "})\n",
    "\n",
    "print(\"\\nCrop production:\")\n",
    "print(crop_prod.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature anomalies:\n",
      "   iso3  year  annual_temp_anomaly_c  growing_season_precip_mm\n",
      "0   CAN  2020                   1.05                     585.0\n",
      "1   CAN  2021                   1.45                     250.0\n",
      "2   CAN  2022                   1.45                     297.0\n",
      "3   CAN  2023                   1.30                     739.0\n",
      "4   USA  2020                   0.64                     564.0\n",
      "5   USA  2021                   1.75                     206.0\n",
      "6   USA  2022                   0.98                     261.0\n",
      "7   USA  2023                   0.78                     598.0\n",
      "8   MEX  2020                   0.56                     203.0\n",
      "9   MEX  2021                   1.39                     296.0\n",
      "10  MEX  2022                   1.52                     529.0\n",
      "11  MEX  2023                   0.52                     615.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Temperature anomalies\n",
    "temp_anomalies = pd.DataFrame({\n",
    "    'iso3': np.repeat(country_codes, len(years)),\n",
    "    'year': np.tile(years, len(country_codes)),\n",
    "    'annual_temp_anomaly_c': np.random.uniform(0.5, 2.0, 40).round(2),\n",
    "    'growing_season_precip_mm': np.random.uniform(200, 800, 40).round(0)\n",
    "})\n",
    "\n",
    "print(\"\\nTemperature anomalies:\")\n",
    "print(temp_anomalies.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building analysis-ready table...\n",
      "  Step 1: Standardizing keys\n",
      "  Step 2: Merging production with countries\n",
      "  Step 3: Merging with climate data\n",
      "  Step 4: Calculating derived metrics\n",
      "  Step 5: Organizing columns\n",
      "  Complete! Shape: (40, 16)\n"
     ]
    }
   ],
   "source": [
    "# Build the analysis-ready table step by step\n",
    "\n",
    "def build_analysis_table(countries, production, climate):\n",
    "    \"\"\"\n",
    "    Build an analysis-ready table combining country, production, and climate data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    countries : pd.DataFrame\n",
    "        Country metadata with country_code as key\n",
    "    production : pd.DataFrame\n",
    "        Crop production data with country_code and year\n",
    "    climate : pd.DataFrame\n",
    "        Climate data with iso3 and year\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Analysis-ready table\n",
    "    \"\"\"\n",
    "    print(\"Building analysis-ready table...\")\n",
    "    \n",
    "    # Step 1: Standardize key columns\n",
    "    print(\"  Step 1: Standardizing keys\")\n",
    "    climate_std = climate.rename(columns={'iso3': 'country_code'})\n",
    "    \n",
    "    # Step 2: Merge production with country metadata\n",
    "    print(\"  Step 2: Merging production with countries\")\n",
    "    df = production.merge(\n",
    "        countries,\n",
    "        on='country_code',\n",
    "        how='left',\n",
    "        validate='many_to_one'\n",
    "    )\n",
    "    \n",
    "    # Step 3: Merge with climate data\n",
    "    print(\"  Step 3: Merging with climate data\")\n",
    "    df = df.merge(\n",
    "        climate_std,\n",
    "        on=['country_code', 'year'],\n",
    "        how='left',\n",
    "        validate='one_to_one'\n",
    "    )\n",
    "    \n",
    "    # Step 4: Add derived metrics\n",
    "    print(\"  Step 4: Calculating derived metrics\")\n",
    "    \n",
    "    # Total production\n",
    "    df['total_cereal_prod_mt'] = df['wheat_prod_mt'] + df['maize_prod_mt']\n",
    "    \n",
    "    # Production per arable land\n",
    "    df['cereal_intensity_mt_per_mha'] = (\n",
    "        df['total_cereal_prod_mt'] / df['arable_land_mha']\n",
    "    ).round(2)\n",
    "    \n",
    "    # Temperature category\n",
    "    df['temp_category'] = pd.cut(\n",
    "        df['annual_temp_anomaly_c'],\n",
    "        bins=[-np.inf, 0.5, 1.0, 1.5, np.inf],\n",
    "        labels=['Normal', 'Warm', 'Hot', 'Very Hot']\n",
    "    )\n",
    "    \n",
    "    # Precipitation category\n",
    "    df['precip_category'] = pd.cut(\n",
    "        df['growing_season_precip_mm'],\n",
    "        bins=[0, 300, 500, 700, np.inf],\n",
    "        labels=['Dry', 'Moderate', 'Wet', 'Very Wet']\n",
    "    )\n",
    "    \n",
    "    # Step 5: Reorder columns logically\n",
    "    print(\"  Step 5: Organizing columns\")\n",
    "    column_order = [\n",
    "        # Keys\n",
    "        'country_code', 'country_name', 'year',\n",
    "        # Geography\n",
    "        'region', 'hemisphere', 'arable_land_mha',\n",
    "        # Production\n",
    "        'wheat_prod_mt', 'maize_prod_mt', 'total_cereal_prod_mt',\n",
    "        'yield_wheat_ton_ha', 'yield_maize_ton_ha', 'cereal_intensity_mt_per_mha',\n",
    "        # Climate\n",
    "        'annual_temp_anomaly_c', 'temp_category',\n",
    "        'growing_season_precip_mm', 'precip_category'\n",
    "    ]\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Step 6: Sort\n",
    "    df = df.sort_values(['country_name', 'year']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"  Complete! Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Build the table\n",
    "analysis_table = build_analysis_table(countries_meta, crop_prod, temp_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis-Ready Table:\n",
      "   country_code country_name  year         region hemisphere  arable_land_mha  \\\n",
      "0           ARG    Argentina  2020  South America   Southern             39.2   \n",
      "1           ARG    Argentina  2021  South America   Southern             39.2   \n",
      "2           ARG    Argentina  2022  South America   Southern             39.2   \n",
      "3           ARG    Argentina  2023  South America   Southern             39.2   \n",
      "4           AUS    Australia  2020        Oceania   Southern             31.2   \n",
      "5           AUS    Australia  2021        Oceania   Southern             31.2   \n",
      "6           AUS    Australia  2022        Oceania   Southern             31.2   \n",
      "7           AUS    Australia  2023        Oceania   Southern             31.2   \n",
      "8           BRA       Brazil  2020  South America   Southern             55.8   \n",
      "9           BRA       Brazil  2021  South America   Southern             55.8   \n",
      "10          BRA       Brazil  2022  South America   Southern             55.8   \n",
      "11          BRA       Brazil  2023  South America   Southern             55.8   \n",
      "12          CAN       Canada  2020  North America   Northern             38.6   \n",
      "13          CAN       Canada  2021  North America   Northern             38.6   \n",
      "14          CAN       Canada  2022  North America   Northern             38.6   \n",
      "15          CAN       Canada  2023  North America   Northern             38.6   \n",
      "\n",
      "    wheat_prod_mt  maize_prod_mt  total_cereal_prod_mt  yield_wheat_ton_ha  \\\n",
      "0            46.1           32.8                  78.9                3.55   \n",
      "1            75.8           70.2                 146.0                3.36   \n",
      "2            63.3           17.7                  81.0                2.55   \n",
      "3            44.3          115.2                 159.5                2.72   \n",
      "4            85.0           27.9                 112.9                2.96   \n",
      "5            11.3          345.4                 356.7                2.65   \n",
      "6            87.0          270.7                 357.7                3.08   \n",
      "7            28.0           71.2                  99.2                2.82   \n",
      "8           117.4          328.9                 446.3                4.02   \n",
      "9            33.7          313.4                 347.1                3.62   \n",
      "10           29.5          210.1                 239.6                4.04   \n",
      "11           29.8          322.8                 352.6                3.49   \n",
      "12           55.6           44.5                 100.1                4.23   \n",
      "13          133.3          174.3                 307.6                3.75   \n",
      "14          103.8           14.0                 117.8                3.16   \n",
      "15           85.8          318.4                 404.2                2.63   \n",
      "\n",
      "    yield_maize_ton_ha  cereal_intensity_mt_per_mha  annual_temp_anomaly_c  \\\n",
      "0                 7.67                         2.01                   1.54   \n",
      "1                 9.33                         3.72                   1.08   \n",
      "2                 6.27                         2.07                   1.91   \n",
      "3                11.75                         4.07                   0.71   \n",
      "4                 3.46                         3.62                   1.29   \n",
      "5                 5.51                        11.43                   0.86   \n",
      "6                11.17                        11.46                   0.64   \n",
      "7                 5.16                         3.18                   1.85   \n",
      "8                 4.08                         8.00                   1.27   \n",
      "9                 6.04                         6.22                   0.84   \n",
      "10               11.49                         4.29                   1.47   \n",
      "11                5.91                         6.32                   0.76   \n",
      "12               10.27                         2.59                   1.05   \n",
      "13               11.06                         7.97                   1.45   \n",
      "14                5.86                         3.05                   1.45   \n",
      "15                3.99                        10.47                   1.30   \n",
      "\n",
      "   temp_category  growing_season_precip_mm precip_category  \n",
      "0       Very Hot                     395.0        Moderate  \n",
      "1            Hot                     648.0             Wet  \n",
      "2       Very Hot                     590.0             Wet  \n",
      "3           Warm                     710.0        Very Wet  \n",
      "4            Hot                     735.0        Very Wet  \n",
      "5           Warm                     579.0             Wet  \n",
      "6           Warm                     677.0             Wet  \n",
      "7       Very Hot                     502.0             Wet  \n",
      "8            Hot                     591.0             Wet  \n",
      "9           Warm                     335.0        Moderate  \n",
      "10           Hot                     627.0             Wet  \n",
      "11          Warm                     342.0        Moderate  \n",
      "12           Hot                     585.0             Wet  \n",
      "13           Hot                     250.0             Dry  \n",
      "14           Hot                     297.0             Dry  \n",
      "15           Hot                     739.0        Very Wet  \n"
     ]
    }
   ],
   "source": [
    "# View the result\n",
    "print(\"Analysis-Ready Table:\")\n",
    "print(analysis_table.head(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average wheat yield by temperature category:\n",
      "temp_category\n",
      "Normal       NaN\n",
      "Warm        3.56\n",
      "Hot         3.55\n",
      "Very Hot    3.38\n",
      "Name: yield_wheat_ton_ha, dtype: float64\n",
      "\n",
      "Total cereal production by region (2023):\n",
      "region\n",
      "Asia              476.5\n",
      "Europe            536.3\n",
      "North America    1116.7\n",
      "Oceania            99.2\n",
      "South America     512.1\n",
      "Name: total_cereal_prod_mt, dtype: float64\n",
      "\n",
      "Hot + Dry country-years:\n",
      "     country_name  year temp_category precip_category  yield_wheat_ton_ha\n",
      "13         Canada  2021           Hot             Dry                3.75\n",
      "14         Canada  2022           Hot             Dry                3.16\n",
      "26        Germany  2022      Very Hot             Dry                3.13\n",
      "29          India  2021      Very Hot             Dry                2.87\n",
      "33         Mexico  2021           Hot             Dry                3.44\n",
      "37  United States  2021      Very Hot             Dry                3.15\n"
     ]
    }
   ],
   "source": [
    "# Now analysis is straightforward\n",
    "\n",
    "# Question 1: Average yield by temperature category\n",
    "print(\"Average wheat yield by temperature category:\")\n",
    "print(analysis_table.groupby('temp_category')['yield_wheat_ton_ha'].mean().round(2))\n",
    "\n",
    "# Question 2: Production by region and year\n",
    "print(\"\\nTotal cereal production by region (2023):\")\n",
    "print(\n",
    "    analysis_table[analysis_table['year'] == 2023]\n",
    "    .groupby('region')['total_cereal_prod_mt']\n",
    "    .sum()\n",
    "    .round(1)\n",
    ")\n",
    "\n",
    "# Question 3: Countries with hot years and low precipitation\n",
    "print(\"\\nHot + Dry country-years:\")\n",
    "hot_dry = analysis_table[\n",
    "    (analysis_table['temp_category'].isin(['Hot', 'Very Hot'])) &\n",
    "    (analysis_table['precip_category'] == 'Dry')\n",
    "]\n",
    "print(hot_dry[['country_name', 'year', 'temp_category', 'precip_category', 'yield_wheat_ton_ha']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Data Contracts and Documentation\n",
    "\n",
    "### What is a Data Contract?\n",
    "\n",
    "A **data contract** is a document that specifies:\n",
    "- What columns exist and their types\n",
    "- What values are allowed\n",
    "- How often data is updated\n",
    "- Who is responsible for the data\n",
    "\n",
    "### Why Contracts Matter\n",
    "\n",
    "Without contracts:\n",
    "- Upstream changes break downstream analysis\n",
    "- Nobody knows what columns mean\n",
    "- Bugs hide in ambiguous data\n",
    "\n",
    "### Simple Contract Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CONTRACT: climate_agriculture_analysis\n",
      "================================================================================\n",
      "\n",
      "Description: Integrated climate and agricultural production data by country and year\n",
      "\n",
      "Generated: 2026-01-26 13:25:37\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SCHEMA\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "country_code:\n",
      "  Type: object\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 10\n",
      "  Sample values: ['ARG', 'AUS', 'BRA', 'CAN', 'CHN']\n",
      "\n",
      "country_name:\n",
      "  Type: object\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 10\n",
      "  Sample values: ['Argentina', 'Australia', 'Brazil', 'Canada', 'China']\n",
      "\n",
      "year:\n",
      "  Type: int64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 4\n",
      "  Range: [2020.00, 2023.00]\n",
      "\n",
      "region:\n",
      "  Type: object\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 5\n",
      "  Sample values: ['South America', 'Oceania', 'North America', 'Asia', 'Europe']\n",
      "\n",
      "hemisphere:\n",
      "  Type: object\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 2\n",
      "  Sample values: ['Southern', 'Northern']\n",
      "\n",
      "arable_land_mha:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 10\n",
      "  Range: [11.80, 157.70]\n",
      "\n",
      "wheat_prod_mt:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 38\n",
      "  Range: [7.80, 135.90]\n",
      "\n",
      "maize_prod_mt:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 40\n",
      "  Range: [3.90, 345.40]\n",
      "\n",
      "total_cereal_prod_mt:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 40\n",
      "  Range: [17.70, 446.30]\n",
      "\n",
      "yield_wheat_ton_ha:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 39\n",
      "  Range: [2.55, 4.36]\n",
      "\n",
      "yield_maize_ton_ha:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 40\n",
      "  Range: [3.06, 11.87]\n",
      "\n",
      "cereal_intensity_mt_per_mha:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 40\n",
      "  Range: [0.15, 28.37]\n",
      "\n",
      "annual_temp_anomaly_c:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 34\n",
      "  Range: [0.52, 1.91]\n",
      "\n",
      "temp_category:\n",
      "  Type: category\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 3\n",
      "  Sample values: ['Very Hot', 'Hot', 'Warm']\n",
      "\n",
      "growing_season_precip_mm:\n",
      "  Type: float64\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 40\n",
      "  Range: [203.00, 784.00]\n",
      "\n",
      "precip_category:\n",
      "  Type: category\n",
      "  Non-null: 40/40 (100.0%)\n",
      "  Unique values: 4\n",
      "  Sample values: ['Moderate', 'Wet', 'Very Wet', 'Dry']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CONSTRAINTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Primary Key: year\n",
      "Foreign Keys: Not specified\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "BUSINESS RULES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "- Numeric measures should be non-negative where applicable\n",
      "- Year should fall within the dataset coverage\n",
      "- Missing values should be represented as NULL in the database\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "REFRESH SCHEDULE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "- Update frequency: Depends on source\n",
      "- Data source: Document per dataset / API\n",
      "- Last updated: Document per refresh run\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas.api.types import (\n",
    "    is_numeric_dtype,\n",
    "    is_datetime64_any_dtype,\n",
    "    is_object_dtype,\n",
    "    is_categorical_dtype,\n",
    ")\n",
    "\n",
    "def generate_data_contract(df, table_name, description):\n",
    "    \"\"\"\n",
    "    Generate a data contract document for a DataFrame.\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "\n",
    "    contract = f\"\"\"\n",
    "================================================================================\n",
    "DATA CONTRACT: {table_name}\n",
    "================================================================================\n",
    "\n",
    "Description: {description}\n",
    "\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "SCHEMA\n",
    "--------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "        dtype_obj = s.dtype\n",
    "        dtype_str = str(dtype_obj)\n",
    "\n",
    "        non_null = int(s.notna().sum())\n",
    "        null_count = int(s.isna().sum())\n",
    "        null_pct = (null_count / n * 100) if n else 0.0\n",
    "        unique = int(s.nunique(dropna=True))\n",
    "\n",
    "        contract += f\"\\n{col}:\\n\"\n",
    "        contract += f\"  Type: {dtype_str}\\n\"\n",
    "        contract += f\"  Non-null: {non_null}/{n} ({(100-null_pct):.1f}%)\\n\"\n",
    "        contract += f\"  Unique values: {unique}\\n\"\n",
    "\n",
    "        # Sample values for categorical/text columns\n",
    "        if is_object_dtype(dtype_obj) or is_categorical_dtype(dtype_obj):\n",
    "            samples = s.dropna().astype(str).unique()[:5]\n",
    "            contract += f\"  Sample values: {list(samples)}\\n\"\n",
    "\n",
    "        # Range for numeric columns\n",
    "        if is_numeric_dtype(dtype_obj):\n",
    "            s_num = pd.to_numeric(s, errors=\"coerce\")\n",
    "            if s_num.notna().any():\n",
    "                contract += f\"  Range: [{s_num.min():.2f}, {s_num.max():.2f}]\\n\"\n",
    "\n",
    "        # Range for datetime columns\n",
    "        elif is_datetime64_any_dtype(dtype_obj):\n",
    "            if s.notna().any():\n",
    "                contract += f\"  Range: [{s.min()}, {s.max()}]\\n\"\n",
    "\n",
    "    # Try to infer keys from available columns (no assumptions beyond names present)\n",
    "    key_cols = [c for c in [\"country_id\", \"year\", \"crop\"] if c in df.columns]\n",
    "    pk_text = \" + \".join(key_cols) if key_cols else \"Not specified\"\n",
    "\n",
    "    fk_text = []\n",
    "    if \"country_id\" in df.columns:\n",
    "        fk_text.append(\"country_id references countries.country_id\")\n",
    "    fk_text = \", \".join(fk_text) if fk_text else \"Not specified\"\n",
    "\n",
    "    contract += f\"\"\"\n",
    "--------------------------------------------------------------------------------\n",
    "CONSTRAINTS\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Primary Key: {pk_text}\n",
    "Foreign Keys: {fk_text}\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "BUSINESS RULES\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "- Numeric measures should be non-negative where applicable\n",
    "- Year should fall within the dataset coverage\n",
    "- Missing values should be represented as NULL in the database\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "REFRESH SCHEDULE\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "- Update frequency: Depends on source\n",
    "- Data source: Document per dataset / API\n",
    "- Last updated: Document per refresh run\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "    return contract\n",
    "\n",
    "# Generate contract for your analysis table (analysis_table must be a DataFrame)\n",
    "contract = generate_data_contract(\n",
    "    analysis_table,\n",
    "    \"climate_agriculture_analysis\",\n",
    "    \"Integrated climate and agricultural production data by country and year\"\n",
    ")\n",
    "\n",
    "print(contract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contract saved to: data_contract_climate_agriculture.md\n"
     ]
    }
   ],
   "source": [
    "# Save contract to file\n",
    "with open('data_contract_climate_agriculture.md', 'w') as f:\n",
    "    f.write(contract)\n",
    "\n",
    "print(\"Contract saved to: data_contract_climate_agriculture.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineage Notes\n",
    "\n",
    "Lineage documents where data came from and how it was transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Logged: Load countries\n",
      "  Logged: Load production\n",
      "  Logged: Load climate\n",
      "  Logged: Merge: production + countries\n",
      "  Logged: Merge: + climate\n",
      "  Logged: Add derived: total_cereal_prod_mt\n",
      "  Logged: Add derived: cereal_intensity\n",
      "  Logged: Add categorical: temp_category\n",
      "\n",
      "============================================================\n",
      "LINEAGE REPORT: climate_agriculture_analysis\n",
      "============================================================\n",
      "Created: 2026-01-26 13:25:37.915030\n",
      "\n",
      "Step 1: Load countries\n",
      "  Details: Source: countries_meta.csv\n",
      "\n",
      "Step 2: Load production\n",
      "  Details: Source: crop_production.csv\n",
      "\n",
      "Step 3: Load climate\n",
      "  Details: Source: temp_anomalies.csv\n",
      "\n",
      "Step 4: Merge: production + countries\n",
      "  Details: Left join on country_code\n",
      "  Input: (40, 6) -> Output: (40, 10)\n",
      "\n",
      "Step 5: Merge: + climate\n",
      "  Details: Left join on country_code, year\n",
      "  Input: (40, 10) -> Output: (40, 12)\n",
      "\n",
      "Step 6: Add derived: total_cereal_prod_mt\n",
      "  Details: wheat + maize\n",
      "  Input: (40, 12) -> Output: (40, 13)\n",
      "\n",
      "Step 7: Add derived: cereal_intensity\n",
      "  Details: total / arable_land\n",
      "  Input: (40, 13) -> Output: (40, 14)\n",
      "\n",
      "Step 8: Add categorical: temp_category\n",
      "  Details: Bins: Normal/Warm/Hot/Very Hot\n",
      "  Input: (40, 14) -> Output: (40, 15)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple lineage tracker\n",
    "\n",
    "class LineageTracker:\n",
    "    \"\"\"\n",
    "    Track data transformations for lineage documentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.steps = []\n",
    "        self.created_at = datetime.now()\n",
    "    \n",
    "    def log(self, operation, details=None, input_shape=None, output_shape=None):\n",
    "        \"\"\"Log a transformation step.\"\"\"\n",
    "        step = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'operation': operation,\n",
    "            'details': details,\n",
    "            'input_shape': input_shape,\n",
    "            'output_shape': output_shape\n",
    "        }\n",
    "        self.steps.append(step)\n",
    "        print(f\"  Logged: {operation}\")\n",
    "    \n",
    "    def report(self):\n",
    "        \"\"\"Generate lineage report.\"\"\"\n",
    "        report = f\"\\n{'='*60}\\n\"\n",
    "        report += f\"LINEAGE REPORT: {self.name}\\n\"\n",
    "        report += f\"{'='*60}\\n\"\n",
    "        report += f\"Created: {self.created_at}\\n\\n\"\n",
    "        \n",
    "        for i, step in enumerate(self.steps, 1):\n",
    "            report += f\"Step {i}: {step['operation']}\\n\"\n",
    "            if step['details']:\n",
    "                report += f\"  Details: {step['details']}\\n\"\n",
    "            if step['input_shape']:\n",
    "                report += f\"  Input: {step['input_shape']} -> Output: {step['output_shape']}\\n\"\n",
    "            report += \"\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "# Example usage\n",
    "lineage = LineageTracker('climate_agriculture_analysis')\n",
    "\n",
    "lineage.log('Load countries', 'Source: countries_meta.csv', None, '(10, 5)')\n",
    "lineage.log('Load production', 'Source: crop_production.csv', None, '(40, 6)')\n",
    "lineage.log('Load climate', 'Source: temp_anomalies.csv', None, '(40, 4)')\n",
    "lineage.log('Merge: production + countries', 'Left join on country_code', '(40, 6)', '(40, 10)')\n",
    "lineage.log('Merge: + climate', 'Left join on country_code, year', '(40, 10)', '(40, 12)')\n",
    "lineage.log('Add derived: total_cereal_prod_mt', 'wheat + maize', '(40, 12)', '(40, 13)')\n",
    "lineage.log('Add derived: cereal_intensity', 'total / arable_land', '(40, 13)', '(40, 14)')\n",
    "lineage.log('Add categorical: temp_category', 'Bins: Normal/Warm/Hot/Very Hot', '(40, 14)', '(40, 15)')\n",
    "\n",
    "print(lineage.report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Key Takeaways\n",
    "\n",
    "### 1. Merging Data\n",
    "- Use `left_on`/`right_on` for different key names\n",
    "- Rename columns first for cleaner code\n",
    "- Chain merges with `.merge().merge()`\n",
    "- Use `validate` to catch problems early\n",
    "\n",
    "### 2. Pivot and Unpivot\n",
    "- `melt()`: Wide to long (unpivot)\n",
    "- `pivot()`: Long to wide (no aggregation)\n",
    "- `pivot_table()`: Long to wide with aggregation\n",
    "- `stack()`/`unstack()`: Move between row and column indices\n",
    "\n",
    "### 3. Analysis-Ready Tables\n",
    "- Tidy structure\n",
    "- Correct types\n",
    "- Derived metrics pre-computed\n",
    "- Logical column order\n",
    "- Clear naming\n",
    "\n",
    "### 4. Documentation\n",
    "- Data contracts specify schema and rules\n",
    "- Lineage tracks transformations\n",
    "- Both are essential for production pipelines\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment 2 Connection\n",
    "\n",
    "In Assignment 2, you will:\n",
    "1. Extract weather data from API (JSON)\n",
    "2. Transform JSON to tidy DataFrame\n",
    "3. Merge with existing crop data from A-1\n",
    "4. Create aggregated views (monthly, annual)\n",
    "5. Build analysis-ready tables for business questions\n",
    "\n",
    "The skills from this lecture are directly applicable!\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "1. **Exercise 1**: Create three DataFrames with different key column names and merge them into one analysis table.\n",
    "\n",
    "2. **Exercise 2**: Take a wide dataset with multiple metrics as columns and convert it to long format, then create a pivot table summarizing by two dimensions.\n",
    "\n",
    "3. **Exercise 3**: Build a complete analysis-ready table that includes at least 3 derived metrics and 2 categorical classifications.\n",
    "\n",
    "4. **Exercise 4**: Write a data contract for a table of your choice, including all constraints and business rules."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
