{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRE 521D: Data Analytics in Climate, Food and Environment\n",
    "\n",
    "## Lecture 2: SQL Refresher - Joins, CTEs, Window Functions, Data Contracts\n",
    "\n",
    "**Date:** January 7, 2026  \n",
    "**Instructor:** Asif Ahmed Neloy  \n",
    "**Term:** Winter 2026\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning Objectives\n",
    "\n",
    "By the end of this lecture, you will be able to:\n",
    "\n",
    "1. Load external data (CSV files) into a MySQL database using Python\n",
    "2. Apply SQL JOINs (INNER, LEFT, RIGHT, CROSS, SELF) to combine related tables\n",
    "3. Write Common Table Expressions (CTEs) for readable, modular queries\n",
    "4. Use window functions for advanced analytics (ranking, running totals, comparisons)\n",
    "5. Define and implement data contracts for quality assurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Dataset Introduction: Air Quality UCI\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "The **Air Quality UCI** dataset contains hourly air quality measurements from a monitoring station in an Italian city. The data was collected from **March 2004 to February 2005** and includes readings from multiple chemical sensors.\n",
    "\n",
    "**Source:** UCI Machine Learning Repository  \n",
    "**Records:** ~9,357 hourly observations  \n",
    "**Period:** March 10, 2004 - April 4, 2005\n",
    "\n",
    "### Column Descriptions\n",
    "\n",
    "| Column | Description | Unit |\n",
    "|--------|-------------|------|\n",
    "| Date | Date of measurement | DD/MM/YYYY |\n",
    "| Time | Time of measurement | HH.MM.SS |\n",
    "| CO(GT) | True hourly averaged CO concentration | mg/m3 |\n",
    "| PT08.S1(CO) | Tin oxide sensor response (CO targeted) | - |\n",
    "| NMHC(GT) | True hourly averaged NMHC concentration | microg/m3 |\n",
    "| C6H6(GT) | True hourly averaged Benzene concentration | microg/m3 |\n",
    "| PT08.S2(NMHC) | Titania sensor response (NMHC targeted) | - |\n",
    "| NOx(GT) | True hourly averaged NOx concentration | ppb |\n",
    "| PT08.S3(NOx) | Tungsten oxide sensor response (NOx targeted) | - |\n",
    "| NO2(GT) | True hourly averaged NO2 concentration | microg/m3 |\n",
    "| PT08.S4(NO2) | Tungsten oxide sensor response (NO2 targeted) | - |\n",
    "| PT08.S5(O3) | Indium oxide sensor response (O3 targeted) | - |\n",
    "| T | Temperature | Celsius |\n",
    "| RH | Relative Humidity | % |\n",
    "| AH | Absolute Humidity | - |\n",
    "\n",
    "### Data Quality Notes\n",
    "\n",
    "- **Missing Values:** Represented as `-200` in the original data\n",
    "- **Decimal Format:** Uses comma as decimal separator (European format)\n",
    "- **Separator:** Semicolon (;) separated values\n",
    "- **(GT)** suffix indicates \"Ground Truth\" measurements from reference analyzers\n",
    "- **PT08.Sx** columns are sensor responses (not direct measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Loading CSV Data into MySQL\n",
    "\n",
    "### 3.1 Setup and Connection\n",
    "\n",
    "First, ensure your MySQL Docker container is running from Lecture 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access is denied.\n",
      "Access is denied.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install pandas pymysql sqlalchemy ipython-sql --quiet\n",
    "%pip install -U cryptography\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load SQL magic extension\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'RuntimeError'> 'cryptography' package is required for sha256_password or caching_sha2_password auth methods\n"
     ]
    }
   ],
   "source": [
    "# # Database connection parameters\n",
    "# DB_USER = \"mfre521d_user\"\n",
    "# DB_PASSWORD = \"mfre521d_user_pw\"\n",
    "# DB_HOST = \"localhost\"\n",
    "# DB_PORT = \"3306\"\n",
    "# DB_NAME = \"mfre521d\"\n",
    "\n",
    "# # Create connection string\n",
    "# connection_string = f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "# # Create SQLAlchemy engine\n",
    "# engine = create_engine(connection_string)\n",
    "\n",
    "# # Connect SQL magic\n",
    "# %sql {connection_string}\n",
    "\n",
    "# Database connection parameters\n",
    "DB_USER = \"mfre521d_user\"\n",
    "DB_PASSWORD = \"mfre521d_user_pw\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"mfre521d\"\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        print(\"Connected OK\")\n",
    "except Exception as e:\n",
    "    print(type(e), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n",
    "%config SqlMagic.autopandas = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Asif Ahmed Neloy\\AppData\\Roaming\\Python\\Python310\\site-packages\\sql\\magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "  File \"C:\\Users\\Asif Ahmed Neloy\\AppData\\Roaming\\Python\\Python310\\site-packages\\sql\\connection.py\", line 82, in set\n",
      "    raise ConnectionError(\n",
      "sql.connection.ConnectionError: Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT 'Connection successful!' AS status, NOW() AS current_ts;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Reading and Cleaning the CSV File\n",
    "\n",
    "The Air Quality dataset has some peculiarities we need to handle:\n",
    "- Semicolon separator\n",
    "- Comma as decimal separator\n",
    "- -200 represents missing values\n",
    "- Empty rows at the end of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Notebook is in: FRE521D-Winter2026-UBC\\Lectures\\Lecture 2 01-07-2026\\\n",
    "# Repo root is:    FRE521D-Winter2026-UBC\\\n",
    "repo_root = Path.cwd().resolve().parents[1]   # up from Lecture folder -> Lectures -> repo root\n",
    "\n",
    "csv_path = repo_root / \"Datasets\" / \"AirQualityUCI.csv\"\n",
    "\n",
    "print(\"Repo root:\", repo_root)\n",
    "print(\"CSV path:\", csv_path)\n",
    "print(\"Exists:\", csv_path.exists())\n",
    "\n",
    "\n",
    "# Read with semicolon separator and European decimal format\n",
    "df_raw = pd.read_csv(\n",
    "    csv_path,\n",
    "    sep=';',\n",
    "    decimal=',',\n",
    "    na_values=['-200', -200],  # Treat -200 as missing\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "print(f\"Raw shape: {df_raw.shape}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names and data types\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframe\n",
    "# 1. Remove empty columns (Unnamed columns)\n",
    "df = df_raw.loc[:, ~df_raw.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# 2. Remove rows where all values are NaN (empty rows)\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# 3. Rename columns to be SQL-friendly (no parentheses, dots)\n",
    "column_mapping = {\n",
    "    'Date': 'reading_date',\n",
    "    'Time': 'reading_time',\n",
    "    'CO(GT)': 'co_gt',\n",
    "    'PT08.S1(CO)': 'pt08_s1_co',\n",
    "    'NMHC(GT)': 'nmhc_gt',\n",
    "    'C6H6(GT)': 'benzene_gt',\n",
    "    'PT08.S2(NMHC)': 'pt08_s2_nmhc',\n",
    "    'NOx(GT)': 'nox_gt',\n",
    "    'PT08.S3(NOx)': 'pt08_s3_nox',\n",
    "    'NO2(GT)': 'no2_gt',\n",
    "    'PT08.S4(NO2)': 'pt08_s4_no2',\n",
    "    'PT08.S5(O3)': 'pt08_s5_o3',\n",
    "    'T': 'temperature',\n",
    "    'RH': 'rel_humidity',\n",
    "    'AH': 'abs_humidity'\n",
    "}\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "print(f\"Cleaned shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create a proper datetime column\n",
    "# The time format is HH.MM.SS, need to convert to HH:MM:SS\n",
    "df['reading_time'] = df['reading_time'].str.replace('.', ':', regex=False)\n",
    "\n",
    "# Combine date and time into datetime\n",
    "df['reading_datetime'] = pd.to_datetime(\n",
    "    df['reading_date'] + ' ' + df['reading_time'],\n",
    "    format='%d/%m/%Y %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Extract useful time components\n",
    "df['hour'] = df['reading_datetime'].dt.hour\n",
    "df['day_of_week'] = df['reading_datetime'].dt.dayofweek\n",
    "df['month'] = df['reading_datetime'].dt.month\n",
    "df['year'] = df['reading_datetime'].dt.year\n",
    "\n",
    "# Add a unique ID\n",
    "df['reading_id'] = range(1, len(df) + 1)\n",
    "\n",
    "print(\"Columns after transformation:\")\n",
    "print(df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values summary\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_pct = (missing_summary / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'missing_count': missing_summary,\n",
    "    'missing_pct': missing_pct\n",
    "})\n",
    "print(\"Missing Values Summary:\")\n",
    "missing_df[missing_df['missing_count'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Loading Data into MySQL\n",
    "\n",
    "We will create multiple tables to demonstrate JOINs:\n",
    "\n",
    "1. **air_quality_readings** - Main fact table with all hourly measurements\n",
    "2. **sensor_info** - Dimension table with metadata about each sensor type\n",
    "3. **daily_summary** - Pre-aggregated daily statistics\n",
    "4. **monthly_summary** - Pre-aggregated monthly statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Drop existing tables if they exist (for clean re-run)\n",
    "DROP TABLE IF EXISTS air_quality_readings;\n",
    "DROP TABLE IF EXISTS sensor_info;\n",
    "DROP TABLE IF EXISTS daily_summary;\n",
    "DROP TABLE IF EXISTS monthly_summary;\n",
    "DROP TABLE IF EXISTS pollution_thresholds;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Create sensor_info table (dimension table)\n",
    "CREATE TABLE sensor_info (\n",
    "    sensor_id INT PRIMARY KEY,\n",
    "    sensor_code VARCHAR(20) NOT NULL,\n",
    "    sensor_name VARCHAR(100) NOT NULL,\n",
    "    measurement_type VARCHAR(50),\n",
    "    unit VARCHAR(20),\n",
    "    is_ground_truth BOOLEAN,\n",
    "    description TEXT\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Insert sensor metadata\n",
    "INSERT INTO sensor_info (sensor_id, sensor_code, sensor_name, measurement_type, unit, is_ground_truth, description)\n",
    "VALUES\n",
    "    (1, 'CO_GT', 'Carbon Monoxide (Ground Truth)', 'CO', 'mg/m3', TRUE, 'True hourly averaged CO concentration from reference analyzer'),\n",
    "    (2, 'PT08_S1_CO', 'Tin Oxide Sensor (CO)', 'CO', 'sensor_response', FALSE, 'Tin oxide sensor response targeted at CO'),\n",
    "    (3, 'NMHC_GT', 'Non-Methane Hydrocarbons (Ground Truth)', 'NMHC', 'microg/m3', TRUE, 'True hourly averaged NMHC concentration'),\n",
    "    (4, 'C6H6_GT', 'Benzene (Ground Truth)', 'Benzene', 'microg/m3', TRUE, 'True hourly averaged Benzene concentration'),\n",
    "    (5, 'PT08_S2_NMHC', 'Titania Sensor (NMHC)', 'NMHC', 'sensor_response', FALSE, 'Titania sensor response targeted at NMHC'),\n",
    "    (6, 'NOX_GT', 'Nitrogen Oxides (Ground Truth)', 'NOx', 'ppb', TRUE, 'True hourly averaged NOx concentration'),\n",
    "    (7, 'PT08_S3_NOX', 'Tungsten Oxide Sensor (NOx)', 'NOx', 'sensor_response', FALSE, 'Tungsten oxide sensor response targeted at NOx'),\n",
    "    (8, 'NO2_GT', 'Nitrogen Dioxide (Ground Truth)', 'NO2', 'microg/m3', TRUE, 'True hourly averaged NO2 concentration'),\n",
    "    (9, 'PT08_S4_NO2', 'Tungsten Oxide Sensor (NO2)', 'NO2', 'sensor_response', FALSE, 'Tungsten oxide sensor response targeted at NO2'),\n",
    "    (10, 'PT08_S5_O3', 'Indium Oxide Sensor (O3)', 'O3', 'sensor_response', FALSE, 'Indium oxide sensor response targeted at O3'),\n",
    "    (11, 'TEMP', 'Temperature', 'Temperature', 'Celsius', TRUE, 'Ambient temperature'),\n",
    "    (12, 'RH', 'Relative Humidity', 'Humidity', '%', TRUE, 'Relative humidity percentage'),\n",
    "    (13, 'AH', 'Absolute Humidity', 'Humidity', 'g/m3', TRUE, 'Absolute humidity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Create pollution thresholds table (for JOIN demonstrations)\n",
    "CREATE TABLE pollution_thresholds (\n",
    "    threshold_id INT PRIMARY KEY,\n",
    "    pollutant VARCHAR(20) NOT NULL,\n",
    "    level_name VARCHAR(20) NOT NULL,\n",
    "    min_value DECIMAL(10,2),\n",
    "    max_value DECIMAL(10,2),\n",
    "    health_advisory TEXT\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Insert pollution threshold data\n",
    "INSERT INTO pollution_thresholds (threshold_id, pollutant, level_name, min_value, max_value, health_advisory)\n",
    "VALUES\n",
    "    (1, 'CO', 'Good', 0, 1.0, 'Air quality is satisfactory'),\n",
    "    (2, 'CO', 'Moderate', 1.0, 2.0, 'Acceptable air quality'),\n",
    "    (3, 'CO', 'Unhealthy-Sensitive', 2.0, 4.0, 'Sensitive groups should limit outdoor activity'),\n",
    "    (4, 'CO', 'Unhealthy', 4.0, 10.0, 'Everyone should limit outdoor activity'),\n",
    "    (5, 'CO', 'Very Unhealthy', 10.0, 999.0, 'Health alert - avoid outdoor activity'),\n",
    "    (6, 'Benzene', 'Good', 0, 5.0, 'Air quality is satisfactory'),\n",
    "    (7, 'Benzene', 'Moderate', 5.0, 10.0, 'Acceptable air quality'),\n",
    "    (8, 'Benzene', 'Unhealthy-Sensitive', 10.0, 15.0, 'Sensitive groups should limit exposure'),\n",
    "    (9, 'Benzene', 'Unhealthy', 15.0, 25.0, 'Everyone should limit exposure'),\n",
    "    (10, 'Benzene', 'Very Unhealthy', 25.0, 999.0, 'Health alert - minimize exposure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Create main readings table\n",
    "CREATE TABLE air_quality_readings (\n",
    "    reading_id INT PRIMARY KEY,\n",
    "    reading_datetime DATETIME NOT NULL,\n",
    "    reading_date DATE,\n",
    "    hour INT,\n",
    "    day_of_week INT,\n",
    "    month INT,\n",
    "    year INT,\n",
    "    co_gt DECIMAL(10,4),\n",
    "    pt08_s1_co DECIMAL(10,2),\n",
    "    nmhc_gt DECIMAL(10,2),\n",
    "    benzene_gt DECIMAL(10,4),\n",
    "    pt08_s2_nmhc DECIMAL(10,2),\n",
    "    nox_gt DECIMAL(10,2),\n",
    "    pt08_s3_nox DECIMAL(10,2),\n",
    "    no2_gt DECIMAL(10,2),\n",
    "    pt08_s4_no2 DECIMAL(10,2),\n",
    "    pt08_s5_o3 DECIMAL(10,2),\n",
    "    temperature DECIMAL(5,2),\n",
    "    rel_humidity DECIMAL(5,2),\n",
    "    abs_humidity DECIMAL(6,4),\n",
    "    INDEX idx_datetime (reading_datetime),\n",
    "    INDEX idx_date (reading_date),\n",
    "    INDEX idx_hour (hour),\n",
    "    INDEX idx_month (month)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe for insertion\n",
    "df_to_insert = df[[\n",
    "    'reading_id', 'reading_datetime', 'reading_date', 'hour', 'day_of_week',\n",
    "    'month', 'year', 'co_gt', 'pt08_s1_co', 'nmhc_gt', 'benzene_gt',\n",
    "    'pt08_s2_nmhc', 'nox_gt', 'pt08_s3_nox', 'no2_gt', 'pt08_s4_no2',\n",
    "    'pt08_s5_o3', 'temperature', 'rel_humidity', 'abs_humidity'\n",
    "]].copy()\n",
    "\n",
    "# Convert reading_date to proper format\n",
    "df_to_insert['reading_date'] = pd.to_datetime(df_to_insert['reading_datetime']).dt.date\n",
    "\n",
    "# Insert data using pandas to_sql\n",
    "df_to_insert.to_sql(\n",
    "    'air_quality_readings',\n",
    "    engine,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    chunksize=1000\n",
    ")\n",
    "\n",
    "print(f\"Inserted {len(df_to_insert)} rows into air_quality_readings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Verify data was inserted\n",
    "SELECT COUNT(*) AS total_rows FROM air_quality_readings;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Create daily summary table\n",
    "CREATE TABLE daily_summary AS\n",
    "SELECT \n",
    "    reading_date,\n",
    "    month,\n",
    "    year,\n",
    "    COUNT(*) AS readings_count,\n",
    "    ROUND(AVG(co_gt), 4) AS avg_co,\n",
    "    ROUND(MAX(co_gt), 4) AS max_co,\n",
    "    ROUND(MIN(co_gt), 4) AS min_co,\n",
    "    ROUND(AVG(benzene_gt), 4) AS avg_benzene,\n",
    "    ROUND(MAX(benzene_gt), 4) AS max_benzene,\n",
    "    ROUND(AVG(nox_gt), 2) AS avg_nox,\n",
    "    ROUND(MAX(nox_gt), 2) AS max_nox,\n",
    "    ROUND(AVG(no2_gt), 2) AS avg_no2,\n",
    "    ROUND(AVG(temperature), 2) AS avg_temp,\n",
    "    ROUND(MIN(temperature), 2) AS min_temp,\n",
    "    ROUND(MAX(temperature), 2) AS max_temp,\n",
    "    ROUND(AVG(rel_humidity), 2) AS avg_humidity\n",
    "FROM air_quality_readings\n",
    "GROUP BY reading_date, month, year\n",
    "ORDER BY reading_date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Create monthly summary table\n",
    "CREATE TABLE monthly_summary AS\n",
    "SELECT \n",
    "    month,\n",
    "    year,\n",
    "    COUNT(*) AS readings_count,\n",
    "    COUNT(DISTINCT reading_date) AS days_with_data,\n",
    "    ROUND(AVG(co_gt), 4) AS avg_co,\n",
    "    ROUND(AVG(benzene_gt), 4) AS avg_benzene,\n",
    "    ROUND(AVG(nox_gt), 2) AS avg_nox,\n",
    "    ROUND(AVG(temperature), 2) AS avg_temp\n",
    "FROM air_quality_readings\n",
    "GROUP BY month, year\n",
    "ORDER BY year, month;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Verify all tables exist\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Insert data using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnamed columns and completely empty columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # Remove \"Unnamed\" columns\n",
    "df = df.dropna(axis=1, how='all')  # Remove columns where all values are NaN\n",
    "\n",
    "# Remove completely empty rows\n",
    "df = df.dropna(axis=0, how='all')  # Remove rows where all values are NaN\n",
    "\n",
    "# Reset index after dropping rows\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the cleaned dataset\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# Function to map Pandas dtypes to MySQL types\n",
    "def map_dtype(dtype):\n",
    "    s = str(dtype)\n",
    "    if \"int\" in s:\n",
    "        return \"INT\"\n",
    "    if \"float\" in s:\n",
    "        return \"DOUBLE\"\n",
    "    if \"bool\" in s:\n",
    "        return \"TINYINT(1)\"\n",
    "    if \"datetime\" in s:\n",
    "        return \"DATETIME\"\n",
    "    return \"VARCHAR(255)\"\n",
    "\n",
    "table_name = \"AirQuality_3\"\n",
    "\n",
    "# Use backticks for MySQL identifiers (not [brackets])\n",
    "columns_sql = \", \".join(\n",
    "    [f\"`{col}` {map_dtype(dtype)}\" for col, dtype in zip(df.columns, df.dtypes)]\n",
    ")\n",
    "\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS `{table_name}` ({columns_sql});\"\n",
    "\n",
    "# Execute the CREATE TABLE statement using SQLAlchemy\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(create_table_query))\n",
    "\n",
    "print(f\"Table {table_name} created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Replace NaN values with None to prevent SQL errors\n",
    "df = df.where(pd.notnull(df), None)\n",
    "\n",
    "# Insert data into SQL table (cursor/conn replaced with SQLAlchemy)\n",
    "with engine.begin() as conn:\n",
    "    for index, row in df.iterrows():\n",
    "        placeholders = \", \".join([f\":p{i}\" for i in range(len(row))])\n",
    "        insert_query = text(f\"INSERT INTO `{table_name}` VALUES ({placeholders})\")\n",
    "\n",
    "        values = []\n",
    "        for v in row:\n",
    "            if v is None:\n",
    "                values.append(None)\n",
    "            elif isinstance(v, float) and math.isnan(v):\n",
    "                values.append(None)\n",
    "            elif isinstance(v, pd.Timestamp):\n",
    "                values.append(v.to_pydatetime())\n",
    "            else:\n",
    "                values.append(v)\n",
    "\n",
    "        params = {f\"p{i}\": values[i] for i in range(len(values))}\n",
    "        conn.execute(insert_query, params)\n",
    "\n",
    "print(f\"Data inserted into {table_name} successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_airquality2 = pd.read_sql(\"SELECT * FROM `AirQuality_3` LIMIT 20;\", engine)\n",
    "df_airquality2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_sql(\"SHOW TABLES;\", engine)\n",
    "tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_airquality = pd.read_sql(\"SELECT * FROM `air_quality_readings` LIMIT 20;\", engine)\n",
    "df_airquality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. SQL JOINs\n",
    "\n",
    "### What are JOINs?\n",
    "\n",
    "JOINs are SQL operations that combine rows from two or more tables based on a related column between them. They are fundamental to working with relational databases where data is normalized across multiple tables.\n",
    "\n",
    "### Why Use JOINs?\n",
    "\n",
    "In a well-designed database, data is organized into separate tables to:\n",
    "- Reduce data redundancy\n",
    "- Maintain data integrity\n",
    "- Improve storage efficiency\n",
    "\n",
    "JOINs allow us to recombine this data when needed for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 INNER JOIN\n",
    "\n",
    "#### Concept\n",
    "\n",
    "An **INNER JOIN** returns only the rows where there is a match in **both** tables. If a row in either table does not have a matching row in the other table, it is excluded from the result.\n",
    "\n",
    "#### Visual Representation\n",
    "\n",
    "```\n",
    "Table A          Table B          INNER JOIN Result\n",
    "+----+----+      +----+----+      +----+----+----+\n",
    "| id | a  |      | id | b  |      | id | a  | b  |\n",
    "+----+----+      +----+----+      +----+----+----+\n",
    "| 1  | A1 |      | 1  | B1 |      | 1  | A1 | B1 |\n",
    "| 2  | A2 |      | 3  | B3 |  =>  | 3  | A3 | B3 |\n",
    "| 3  | A3 |      | 4  | B4 |      +----+----+----+\n",
    "+----+----+      +----+----+      (Only matching IDs)\n",
    "```\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```sql\n",
    "SELECT columns\n",
    "FROM table_a\n",
    "INNER JOIN table_b ON table_a.key = table_b.key;\n",
    "```\n",
    "\n",
    "#### When to Use\n",
    "\n",
    "- When you only want records that have matching data in both tables\n",
    "- Most common type of JOIN for combining related data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 1: Which hourly readings had CO levels in the \"Unhealthy\" range?\n",
    "\n",
    "We will JOIN the readings table with the pollution thresholds table to classify each reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- INNER JOIN: Classify CO readings by pollution level\n",
    "SELECT \n",
    "    r.reading_datetime,\n",
    "    r.co_gt AS co_level,\n",
    "    p.level_name,\n",
    "    p.health_advisory\n",
    "FROM air_quality_readings r\n",
    "INNER JOIN pollution_thresholds p \n",
    "    ON p.pollutant = 'CO'\n",
    "    AND r.co_gt >= p.min_value \n",
    "    AND r.co_gt < p.max_value\n",
    "WHERE r.co_gt IS NOT NULL\n",
    "ORDER BY r.co_gt DESC\n",
    "LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 2: How many readings fall into each pollution category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- INNER JOIN: Count readings by pollution level\n",
    "SELECT \n",
    "    p.level_name,\n",
    "    p.min_value,\n",
    "    p.max_value,\n",
    "    COUNT(r.reading_id) AS reading_count,\n",
    "    ROUND(COUNT(r.reading_id) * 100.0 / \n",
    "          (SELECT COUNT(*) FROM air_quality_readings WHERE co_gt IS NOT NULL), 2) AS percentage\n",
    "FROM pollution_thresholds p\n",
    "INNER JOIN air_quality_readings r \n",
    "    ON p.pollutant = 'CO'\n",
    "    AND r.co_gt >= p.min_value \n",
    "    AND r.co_gt < p.max_value\n",
    "WHERE r.co_gt IS NOT NULL\n",
    "GROUP BY p.level_name, p.min_value, p.max_value\n",
    "ORDER BY p.min_value;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 LEFT JOIN (LEFT OUTER JOIN)\n",
    "\n",
    "#### Concept\n",
    "\n",
    "A **LEFT JOIN** returns **all rows from the left table** and the matching rows from the right table. If there is no match, NULL values are returned for columns from the right table.\n",
    "\n",
    "#### Visual Representation\n",
    "\n",
    "```\n",
    "Table A          Table B          LEFT JOIN Result\n",
    "+----+----+      +----+----+      +----+----+------+\n",
    "| id | a  |      | id | b  |      | id | a  | b    |\n",
    "+----+----+      +----+----+      +----+----+------+\n",
    "| 1  | A1 |      | 1  | B1 |      | 1  | A1 | B1   |\n",
    "| 2  | A2 |      | 3  | B3 |  =>  | 2  | A2 | NULL |\n",
    "| 3  | A3 |      | 4  | B4 |      | 3  | A3 | B3   |\n",
    "+----+----+      +----+----+      +----+----+------+\n",
    "                                  (All from A, matches from B)\n",
    "```\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```sql\n",
    "SELECT columns\n",
    "FROM table_a\n",
    "LEFT JOIN table_b ON table_a.key = table_b.key;\n",
    "```\n",
    "\n",
    "#### When to Use\n",
    "\n",
    "- When you want all records from the primary (left) table regardless of matches\n",
    "- Finding records that do NOT have a match (using WHERE right_table.key IS NULL)\n",
    "- Preserving all data from the main table while adding optional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 3: Show all days with their summary statistics, including days with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- LEFT JOIN: Get daily summaries with monthly context\n",
    "SELECT \n",
    "    d.reading_date,\n",
    "    d.avg_co AS daily_avg_co,\n",
    "    m.avg_co AS monthly_avg_co,\n",
    "    ROUND(d.avg_co - m.avg_co, 4) AS deviation_from_monthly,\n",
    "    CASE \n",
    "        WHEN d.avg_co > m.avg_co THEN 'Above Average'\n",
    "        WHEN d.avg_co < m.avg_co THEN 'Below Average'\n",
    "        ELSE 'Average'\n",
    "    END AS comparison\n",
    "FROM daily_summary d\n",
    "LEFT JOIN monthly_summary m \n",
    "    ON d.month = m.month AND d.year = m.year\n",
    "WHERE d.avg_co IS NOT NULL\n",
    "ORDER BY d.reading_date\n",
    "LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 4: Find pollution thresholds that have no matching readings (identify unused categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- LEFT JOIN to find unmatched records\n",
    "SELECT \n",
    "    p.pollutant,\n",
    "    p.level_name,\n",
    "    p.min_value,\n",
    "    p.max_value,\n",
    "    COUNT(r.reading_id) AS matching_readings\n",
    "FROM pollution_thresholds p\n",
    "LEFT JOIN air_quality_readings r \n",
    "    ON (p.pollutant = 'CO' AND r.co_gt >= p.min_value AND r.co_gt < p.max_value)\n",
    "    OR (p.pollutant = 'Benzene' AND r.benzene_gt >= p.min_value AND r.benzene_gt < p.max_value)\n",
    "GROUP BY p.pollutant, p.level_name, p.min_value, p.max_value\n",
    "ORDER BY p.pollutant, p.min_value;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 RIGHT JOIN (RIGHT OUTER JOIN)\n",
    "\n",
    "#### Concept\n",
    "\n",
    "A **RIGHT JOIN** returns **all rows from the right table** and the matching rows from the left table. If there is no match, NULL values are returned for columns from the left table.\n",
    "\n",
    "#### Visual Representation\n",
    "\n",
    "```\n",
    "Table A          Table B          RIGHT JOIN Result\n",
    "+----+----+      +----+----+      +------+----+----+\n",
    "| id | a  |      | id | b  |      | a    | id | b  |\n",
    "+----+----+      +----+----+      +------+----+----+\n",
    "| 1  | A1 |      | 1  | B1 |      | A1   | 1  | B1 |\n",
    "| 2  | A2 |      | 3  | B3 |  =>  | A3   | 3  | B3 |\n",
    "| 3  | A3 |      | 4  | B4 |      | NULL | 4  | B4 |\n",
    "+----+----+      +----+----+      +------+----+----+\n",
    "                                  (All from B, matches from A)\n",
    "```\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```sql\n",
    "SELECT columns\n",
    "FROM table_a\n",
    "RIGHT JOIN table_b ON table_a.key = table_b.key;\n",
    "```\n",
    "\n",
    "#### When to Use\n",
    "\n",
    "- When you want all records from the secondary (right) table\n",
    "- Less common than LEFT JOIN (you can usually rewrite as LEFT JOIN by swapping table order)\n",
    "- Useful when the query logic naturally flows left-to-right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 5: Show all months and their data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- RIGHT JOIN: Ensure all monthly summaries are shown with their daily details\n",
    "SELECT \n",
    "    m.month,\n",
    "    m.year,\n",
    "    m.avg_co AS monthly_avg_co,\n",
    "    COUNT(d.reading_date) AS days_in_month,\n",
    "    ROUND(AVG(d.avg_co), 4) AS recalculated_avg_co\n",
    "FROM daily_summary d\n",
    "RIGHT JOIN monthly_summary m \n",
    "    ON d.month = m.month AND d.year = m.year\n",
    "GROUP BY m.month, m.year, m.avg_co\n",
    "ORDER BY m.year, m.month;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 CROSS JOIN\n",
    "\n",
    "#### Concept\n",
    "\n",
    "A **CROSS JOIN** returns the **Cartesian product** of both tables - every row from the first table is combined with every row from the second table. No join condition is specified.\n",
    "\n",
    "#### Visual Representation\n",
    "\n",
    "```\n",
    "Table A      Table B      CROSS JOIN Result\n",
    "+----+       +----+       +----+----+\n",
    "| a  |       | b  |       | a  | b  |\n",
    "+----+       +----+       +----+----+\n",
    "| A1 |       | B1 |       | A1 | B1 |\n",
    "| A2 |   X   | B2 |   =>  | A1 | B2 |\n",
    "+----+       +----+       | A2 | B1 |\n",
    "                          | A2 | B2 |\n",
    "                          +----+----+\n",
    "                          (2 x 2 = 4 rows)\n",
    "```\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```sql\n",
    "SELECT columns\n",
    "FROM table_a\n",
    "CROSS JOIN table_b;\n",
    "```\n",
    "\n",
    "#### When to Use\n",
    "\n",
    "- Generating all possible combinations\n",
    "- Creating lookup tables or calendars\n",
    "- Comparing every row in one table to every row in another\n",
    "- **Caution:** Result size = rows_in_A * rows_in_B (can be very large!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 6: Compare average CO levels across all months (create a comparison matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- CROSS JOIN: Compare each month's CO level to every other month\n",
    "SELECT \n",
    "    m1.month AS month_1,\n",
    "    m1.year AS year_1,\n",
    "    m1.avg_co AS co_month_1,\n",
    "    m2.month AS month_2,\n",
    "    m2.year AS year_2,\n",
    "    m2.avg_co AS co_month_2,\n",
    "    ROUND(m1.avg_co - m2.avg_co, 4) AS co_difference\n",
    "FROM monthly_summary m1\n",
    "CROSS JOIN monthly_summary m2\n",
    "WHERE m1.month != m2.month OR m1.year != m2.year\n",
    "ORDER BY ABS(m1.avg_co - m2.avg_co) DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 SELF JOIN\n",
    "\n",
    "#### Concept\n",
    "\n",
    "A **SELF JOIN** is when a table is joined with itself. This is useful for comparing rows within the same table or finding relationships between records in the same table.\n",
    "\n",
    "#### Visual Representation\n",
    "\n",
    "```\n",
    "employees table                    SELF JOIN (Find managers)\n",
    "+----+-------+------------+        +----------+-------------+\n",
    "| id | name  | manager_id |        | employee | manager     |\n",
    "+----+-------+------------+        +----------+-------------+\n",
    "| 1  | Alice | NULL       |        | Bob      | Alice       |\n",
    "| 2  | Bob   | 1          |   =>   | Carol    | Bob         |\n",
    "| 3  | Carol | 2          |        +----------+-------------+\n",
    "+----+-------+------------+\n",
    "```\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```sql\n",
    "SELECT columns\n",
    "FROM table_a AS a1\n",
    "JOIN table_a AS a2 ON a1.some_column = a2.other_column;\n",
    "```\n",
    "\n",
    "#### When to Use\n",
    "\n",
    "- Comparing rows within the same table\n",
    "- Finding sequential records (previous/next)\n",
    "- Hierarchical data (employees and managers)\n",
    "- Time-series comparisons (today vs yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 7: Compare each day's pollution to the previous day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- SELF JOIN: Compare each day to the previous day\n",
    "SELECT \n",
    "    curr.reading_date AS current_date,\n",
    "    curr.avg_co AS current_co,\n",
    "    prev.reading_date AS previous_date,\n",
    "    prev.avg_co AS previous_co,\n",
    "    ROUND(curr.avg_co - prev.avg_co, 4) AS co_change,\n",
    "    CASE \n",
    "        WHEN curr.avg_co > prev.avg_co * 1.5 THEN 'Significant Increase'\n",
    "        WHEN curr.avg_co < prev.avg_co * 0.5 THEN 'Significant Decrease'\n",
    "        WHEN curr.avg_co > prev.avg_co THEN 'Increase'\n",
    "        WHEN curr.avg_co < prev.avg_co THEN 'Decrease'\n",
    "        ELSE 'No Change'\n",
    "    END AS trend\n",
    "FROM daily_summary curr\n",
    "INNER JOIN daily_summary prev \n",
    "    ON curr.reading_date = DATE_ADD(prev.reading_date, INTERVAL 1 DAY)\n",
    "WHERE curr.avg_co IS NOT NULL AND prev.avg_co IS NOT NULL\n",
    "ORDER BY curr.reading_date\n",
    "LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Common Table Expressions (CTEs)\n",
    "\n",
    "### What are CTEs?\n",
    "\n",
    "A **Common Table Expression (CTE)** is a temporary named result set that exists only within the scope of a single SQL statement. Think of it as creating a temporary \"view\" that you can reference in your main query.\n",
    "\n",
    "### Benefits of CTEs\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Readability** | Break complex queries into logical, named steps |\n",
    "| **Reusability** | Reference the same CTE multiple times in one query |\n",
    "| **Maintainability** | Easier to debug and modify individual parts |\n",
    "| **Organization** | Separate data preparation from final analysis |\n",
    "\n",
    "### Basic Syntax\n",
    "\n",
    "```sql\n",
    "WITH cte_name AS (\n",
    "    -- Your query here\n",
    "    SELECT column1, column2\n",
    "    FROM some_table\n",
    "    WHERE condition\n",
    ")\n",
    "SELECT *\n",
    "FROM cte_name;\n",
    "```\n",
    "\n",
    "### Multiple CTEs Syntax\n",
    "\n",
    "```sql\n",
    "WITH \n",
    "    cte_first AS (\n",
    "        SELECT ...\n",
    "    ),\n",
    "    cte_second AS (\n",
    "        SELECT ...\n",
    "        FROM cte_first  -- Can reference previous CTEs\n",
    "    )\n",
    "SELECT *\n",
    "FROM cte_second;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Single CTE\n",
    "\n",
    "#### Concept\n",
    "\n",
    "A single CTE is useful for:\n",
    "- Pre-filtering or aggregating data before the main query\n",
    "- Making complex subqueries more readable\n",
    "- Calculating intermediate values\n",
    "\n",
    "#### Example Structure\n",
    "\n",
    "```sql\n",
    "WITH filtered_data AS (\n",
    "    SELECT *\n",
    "    FROM raw_table\n",
    "    WHERE quality_flag = 'GOOD'\n",
    ")\n",
    "SELECT AVG(value)\n",
    "FROM filtered_data;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 9: Which hours of the day have the worst air quality (highest average CO)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Single CTE: Calculate and classify hourly averages\n",
    "WITH hourly_averages AS (\n",
    "    SELECT \n",
    "        hour,\n",
    "        ROUND(AVG(co_gt), 4) AS avg_co,\n",
    "        ROUND(AVG(benzene_gt), 4) AS avg_benzene,\n",
    "        ROUND(AVG(nox_gt), 2) AS avg_nox,\n",
    "        COUNT(*) AS reading_count\n",
    "    FROM air_quality_readings\n",
    "    WHERE co_gt IS NOT NULL\n",
    "    GROUP BY hour\n",
    ")\n",
    "SELECT \n",
    "    hour,\n",
    "    avg_co,\n",
    "    avg_benzene,\n",
    "    avg_nox,\n",
    "    reading_count,\n",
    "    CASE \n",
    "        WHEN avg_co > 2.5 THEN 'High Pollution'\n",
    "        WHEN avg_co > 1.5 THEN 'Moderate Pollution'\n",
    "        ELSE 'Low Pollution'\n",
    "    END AS pollution_category\n",
    "FROM hourly_averages\n",
    "ORDER BY avg_co DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Multiple CTEs (Chained)\n",
    "\n",
    "#### Concept\n",
    "\n",
    "Multiple CTEs allow you to build complex analysis step by step. Each CTE can reference previously defined CTEs.\n",
    "\n",
    "#### Example Structure\n",
    "\n",
    "```sql\n",
    "WITH \n",
    "    step1 AS (\n",
    "        -- First calculation\n",
    "        SELECT ...\n",
    "    ),\n",
    "    step2 AS (\n",
    "        -- Build on step1\n",
    "        SELECT ...\n",
    "        FROM step1\n",
    "    ),\n",
    "    step3 AS (\n",
    "        -- Combine or further process\n",
    "        SELECT ...\n",
    "        FROM step2\n",
    "    )\n",
    "SELECT * FROM step3;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 10: Find days where pollution was significantly above monthly average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Multiple CTEs: Step-by-step analysis\n",
    "WITH \n",
    "    -- Step 1: Calculate daily averages\n",
    "    daily_pollution AS (\n",
    "        SELECT \n",
    "            reading_date,\n",
    "            month,\n",
    "            year,\n",
    "            ROUND(AVG(co_gt), 4) AS daily_avg_co,\n",
    "            ROUND(AVG(benzene_gt), 4) AS daily_avg_benzene\n",
    "        FROM air_quality_readings\n",
    "        WHERE co_gt IS NOT NULL\n",
    "        GROUP BY reading_date, month, year\n",
    "    ),\n",
    "    -- Step 2: Calculate monthly baselines\n",
    "    monthly_baseline AS (\n",
    "        SELECT \n",
    "            month,\n",
    "            year,\n",
    "            ROUND(AVG(daily_avg_co), 4) AS monthly_avg_co,\n",
    "            ROUND(STDDEV(daily_avg_co), 4) AS monthly_std_co\n",
    "        FROM daily_pollution\n",
    "        GROUP BY month, year\n",
    "    ),\n",
    "    -- Step 3: Compare daily to monthly\n",
    "    daily_comparison AS (\n",
    "        SELECT \n",
    "            d.reading_date,\n",
    "            d.daily_avg_co,\n",
    "            m.monthly_avg_co,\n",
    "            m.monthly_std_co,\n",
    "            ROUND(d.daily_avg_co - m.monthly_avg_co, 4) AS deviation,\n",
    "            ROUND((d.daily_avg_co - m.monthly_avg_co) / m.monthly_std_co, 2) AS z_score\n",
    "        FROM daily_pollution d\n",
    "        JOIN monthly_baseline m ON d.month = m.month AND d.year = m.year\n",
    "    )\n",
    "-- Final query: Find outlier days (z-score > 2)\n",
    "SELECT \n",
    "    reading_date,\n",
    "    daily_avg_co,\n",
    "    monthly_avg_co,\n",
    "    deviation,\n",
    "    z_score,\n",
    "    CASE \n",
    "        WHEN z_score > 2 THEN 'Significantly High'\n",
    "        WHEN z_score < -2 THEN 'Significantly Low'\n",
    "        ELSE 'Normal'\n",
    "    END AS status\n",
    "FROM daily_comparison\n",
    "WHERE ABS(z_score) > 1.5\n",
    "ORDER BY z_score DESC\n",
    "LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 11: Data Quality Assessment - Which sensors have the most missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Multiple CTEs: Comprehensive data quality assessment\n",
    "WITH \n",
    "    total_count AS (\n",
    "        SELECT COUNT(*) AS total FROM air_quality_readings\n",
    "    ),\n",
    "    missing_by_sensor AS (\n",
    "        SELECT 'CO (Ground Truth)' AS sensor, SUM(CASE WHEN co_gt IS NULL THEN 1 ELSE 0 END) AS missing\n",
    "        FROM air_quality_readings\n",
    "        UNION ALL\n",
    "        SELECT 'Benzene (Ground Truth)', SUM(CASE WHEN benzene_gt IS NULL THEN 1 ELSE 0 END)\n",
    "        FROM air_quality_readings\n",
    "        UNION ALL\n",
    "        SELECT 'NOx (Ground Truth)', SUM(CASE WHEN nox_gt IS NULL THEN 1 ELSE 0 END)\n",
    "        FROM air_quality_readings\n",
    "        UNION ALL\n",
    "        SELECT 'NO2 (Ground Truth)', SUM(CASE WHEN no2_gt IS NULL THEN 1 ELSE 0 END)\n",
    "        FROM air_quality_readings\n",
    "        UNION ALL\n",
    "        SELECT 'NMHC (Ground Truth)', SUM(CASE WHEN nmhc_gt IS NULL THEN 1 ELSE 0 END)\n",
    "        FROM air_quality_readings\n",
    "        UNION ALL\n",
    "        SELECT 'Temperature', SUM(CASE WHEN temperature IS NULL THEN 1 ELSE 0 END)\n",
    "        FROM air_quality_readings\n",
    "        UNION ALL\n",
    "        SELECT 'Humidity', SUM(CASE WHEN rel_humidity IS NULL THEN 1 ELSE 0 END)\n",
    "        FROM air_quality_readings\n",
    "    )\n",
    "SELECT \n",
    "    m.sensor,\n",
    "    m.missing AS missing_count,\n",
    "    t.total AS total_readings,\n",
    "    ROUND(m.missing * 100.0 / t.total, 2) AS missing_percentage,\n",
    "    CASE \n",
    "        WHEN m.missing * 100.0 / t.total > 20 THEN 'Critical - Needs Attention'\n",
    "        WHEN m.missing * 100.0 / t.total > 10 THEN 'Warning - Review Required'\n",
    "        WHEN m.missing * 100.0 / t.total > 5 THEN 'Acceptable'\n",
    "        ELSE 'Good Quality'\n",
    "    END AS quality_status\n",
    "FROM missing_by_sensor m\n",
    "CROSS JOIN total_count t\n",
    "ORDER BY missing_percentage DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Window Functions\n",
    "\n",
    "### What are Window Functions?\n",
    "\n",
    "**Window functions** perform calculations across a set of rows that are related to the current row. Unlike GROUP BY which collapses rows into groups, window functions keep all individual rows while adding calculated values.\n",
    "\n",
    "### Key Difference: GROUP BY vs Window Functions\n",
    "\n",
    "```\n",
    "Original Data:          GROUP BY Result:       Window Function Result:\n",
    "+------+-------+        +------+-------+       +------+-------+-------+\n",
    "| dept | sales |        | dept | total |       | dept | sales | total |\n",
    "+------+-------+        +------+-------+       +------+-------+-------+\n",
    "| A    | 100   |        | A    | 300   |       | A    | 100   | 300   |\n",
    "| A    | 200   |   =>   | B    | 150   |       | A    | 200   | 300   |\n",
    "| B    | 150   |        +------+-------+       | B    | 150   | 150   |\n",
    "+------+-------+        (Rows collapsed)       +------+-------+-------+\n",
    "                                               (All rows preserved)\n",
    "```\n",
    "\n",
    "### Window Function Syntax\n",
    "\n",
    "```sql\n",
    "function_name(column) OVER (\n",
    "    [PARTITION BY partition_column]\n",
    "    [ORDER BY order_column]\n",
    "    [ROWS/RANGE frame_specification]\n",
    ")\n",
    "```\n",
    "\n",
    "### Common Window Functions\n",
    "\n",
    "| Function | Description | Example Use Case |\n",
    "|----------|-------------|------------------|\n",
    "| ROW_NUMBER() | Unique sequential number | Assign IDs, pagination |\n",
    "| RANK() | Rank with gaps for ties | Competition rankings |\n",
    "| DENSE_RANK() | Rank without gaps | Dense rankings |\n",
    "| LAG(col, n) | Value from n rows before | Compare to previous period |\n",
    "| LEAD(col, n) | Value from n rows after | Compare to next period |\n",
    "| SUM() OVER | Running/cumulative total | Running balance |\n",
    "| AVG() OVER | Moving average | Trend smoothing |\n",
    "| FIRST_VALUE() | First value in window | Get baseline value |\n",
    "| LAST_VALUE() | Last value in window | Get latest value |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 ROW_NUMBER, RANK, and DENSE_RANK\n",
    "\n",
    "#### Concept\n",
    "\n",
    "These functions assign a number to each row based on the specified ordering:\n",
    "\n",
    "```\n",
    "Data:     ROW_NUMBER:   RANK:    DENSE_RANK:\n",
    "+-----+   +-----+       +-----+  +-----+\n",
    "| 100 |   |  1  |       |  1  |  |  1  |\n",
    "| 100 |   |  2  |       |  1  |  |  1  |\n",
    "| 90  |   |  3  |       |  3  |  |  2  |\n",
    "| 80  |   |  4  |       |  4  |  |  3  |\n",
    "+-----+   +-----+       +-----+  +-----+\n",
    "          (unique)      (gaps)   (no gaps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 12: Rank each hour's pollution level within its day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- ROW_NUMBER, RANK, DENSE_RANK comparison\n",
    "SELECT \n",
    "    reading_date,\n",
    "    hour,\n",
    "    co_gt,\n",
    "    ROW_NUMBER() OVER (PARTITION BY reading_date ORDER BY co_gt DESC) AS row_num,\n",
    "    RANK() OVER (PARTITION BY reading_date ORDER BY co_gt DESC) AS rank_num,\n",
    "    DENSE_RANK() OVER (PARTITION BY reading_date ORDER BY co_gt DESC) AS dense_rank_num\n",
    "FROM air_quality_readings\n",
    "WHERE co_gt IS NOT NULL\n",
    "    AND reading_date = '2004-03-15'\n",
    "ORDER BY row_num;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 13: Find the top 3 most polluted hours for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Get top 3 polluted hours per day using ROW_NUMBER\n",
    "WITH ranked_hours AS (\n",
    "    SELECT \n",
    "        reading_date,\n",
    "        hour,\n",
    "        co_gt,\n",
    "        ROW_NUMBER() OVER (PARTITION BY reading_date ORDER BY co_gt DESC) AS pollution_rank\n",
    "    FROM air_quality_readings\n",
    "    WHERE co_gt IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "    reading_date,\n",
    "    hour,\n",
    "    co_gt,\n",
    "    pollution_rank\n",
    "FROM ranked_hours\n",
    "WHERE pollution_rank <= 3\n",
    "ORDER BY reading_date, pollution_rank\n",
    "LIMIT 21;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 LAG and LEAD\n",
    "\n",
    "#### Concept\n",
    "\n",
    "LAG and LEAD allow you to access values from previous or subsequent rows:\n",
    "\n",
    "```\n",
    "Current Row           LAG(value, 1)        LEAD(value, 1)\n",
    "+-----+-----+         +-----+------+       +-----+------+\n",
    "| row | val |         | row | prev |       | row | next |\n",
    "+-----+-----+         +-----+------+       +-----+------+\n",
    "| 1   | A   |         | 1   | NULL |       | 1   | B    |\n",
    "| 2   | B   |    =>   | 2   | A    |       | 2   | C    |\n",
    "| 3   | C   |         | 3   | B    |       | 3   | NULL |\n",
    "+-----+-----+         +-----+------+       +-----+------+\n",
    "```\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```sql\n",
    "LAG(column, offset, default) OVER (ORDER BY ...)\n",
    "LEAD(column, offset, default) OVER (ORDER BY ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 14: How does each hour's pollution compare to the previous hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- LAG: Compare to previous hour\n",
    "SELECT \n",
    "    reading_datetime,\n",
    "    co_gt AS current_co,\n",
    "    LAG(co_gt, 1) OVER (ORDER BY reading_datetime) AS previous_hour_co,\n",
    "    LEAD(co_gt, 1) OVER (ORDER BY reading_datetime) AS next_hour_co,\n",
    "    ROUND(co_gt - LAG(co_gt, 1) OVER (ORDER BY reading_datetime), 4) AS hourly_change,\n",
    "    CASE \n",
    "        WHEN co_gt - LAG(co_gt, 1) OVER (ORDER BY reading_datetime) > 1 THEN 'Spike'\n",
    "        WHEN co_gt - LAG(co_gt, 1) OVER (ORDER BY reading_datetime) < -1 THEN 'Drop'\n",
    "        ELSE 'Stable'\n",
    "    END AS trend\n",
    "FROM air_quality_readings\n",
    "WHERE co_gt IS NOT NULL\n",
    "ORDER BY reading_datetime\n",
    "LIMIT 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 15: Detect sudden pollution spikes (hour-over-hour increase > 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Find pollution spikes using LAG\n",
    "WITH hourly_changes AS (\n",
    "    SELECT \n",
    "        reading_datetime,\n",
    "        co_gt,\n",
    "        LAG(co_gt, 1) OVER (ORDER BY reading_datetime) AS prev_co,\n",
    "        co_gt - LAG(co_gt, 1) OVER (ORDER BY reading_datetime) AS absolute_change\n",
    "    FROM air_quality_readings\n",
    "    WHERE co_gt IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "    reading_datetime,\n",
    "    prev_co AS previous_co,\n",
    "    co_gt AS current_co,\n",
    "    absolute_change,\n",
    "    ROUND(absolute_change * 100.0 / prev_co, 2) AS percent_change\n",
    "FROM hourly_changes\n",
    "WHERE prev_co > 0 \n",
    "    AND absolute_change > 0\n",
    "    AND (absolute_change / prev_co) > 0.5  -- More than 50% increase\n",
    "ORDER BY absolute_change DESC\n",
    "LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Running Totals and Moving Averages\n",
    "\n",
    "#### Concept\n",
    "\n",
    "Window functions can calculate cumulative sums and moving averages:\n",
    "\n",
    "```\n",
    "Data:    Running Sum:   3-Period Moving Avg:\n",
    "+-----+  +-----+        +-------+\n",
    "| 10  |  | 10  |        | NULL  |  (not enough data)\n",
    "| 20  |  | 30  |        | NULL  |  (not enough data)\n",
    "| 30  |  | 60  |        | 20.0  |  (10+20+30)/3\n",
    "| 40  |  | 100 |        | 30.0  |  (20+30+40)/3\n",
    "+-----+  +-----+        +-------+\n",
    "```\n",
    "\n",
    "#### Frame Specification\n",
    "\n",
    "```sql\n",
    "SUM(col) OVER (\n",
    "    ORDER BY date\n",
    "    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW  -- Last 3 rows\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 16: Calculate 7-day moving average of CO levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- 7-day moving average using window function\n",
    "SELECT \n",
    "    reading_date,\n",
    "    avg_co AS daily_co,\n",
    "    ROUND(AVG(avg_co) OVER (\n",
    "        ORDER BY reading_date\n",
    "        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "    ), 4) AS moving_avg_7day,\n",
    "    ROUND(AVG(avg_co) OVER (\n",
    "        ORDER BY reading_date\n",
    "        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW\n",
    "    ), 4) AS moving_avg_14day\n",
    "FROM daily_summary\n",
    "WHERE avg_co IS NOT NULL\n",
    "ORDER BY reading_date\n",
    "LIMIT 30;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Question 17: Calculate cumulative pollution exposure over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Running total of pollution exposure\n",
    "SELECT \n",
    "    reading_date,\n",
    "    avg_co,\n",
    "    SUM(avg_co) OVER (ORDER BY reading_date) AS cumulative_co_exposure,\n",
    "    ROW_NUMBER() OVER (ORDER BY reading_date) AS day_number,\n",
    "    ROUND(SUM(avg_co) OVER (ORDER BY reading_date) / \n",
    "          ROW_NUMBER() OVER (ORDER BY reading_date), 4) AS running_avg_co\n",
    "FROM daily_summary\n",
    "WHERE avg_co IS NOT NULL\n",
    "ORDER BY reading_date\n",
    "LIMIT 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Data Contracts\n",
    "\n",
    "### What are Data Contracts?\n",
    "\n",
    "A **data contract** is a formal agreement that defines the structure, format, and quality expectations for data. It serves as documentation and can be enforced through database constraints.\n",
    "\n",
    "### Types of Data Contracts\n",
    "\n",
    "| Contract Type | Description | Implementation |\n",
    "|---------------|-------------|----------------|\n",
    "| **Schema Contract** | Defines column names and data types | CREATE TABLE statement |\n",
    "| **Not Null Contract** | Specifies required fields | NOT NULL constraint |\n",
    "| **Uniqueness Contract** | Ensures unique values | UNIQUE or PRIMARY KEY |\n",
    "| **Range Contract** | Defines valid value ranges | CHECK constraint |\n",
    "| **Referential Contract** | Links between tables | FOREIGN KEY constraint |\n",
    "| **Format Contract** | Specifies data format | Application validation |\n",
    "\n",
    "### Why Data Contracts Matter\n",
    "\n",
    "1. **Data Quality:** Prevent bad data from entering the system\n",
    "2. **Consistency:** Ensure all data follows the same rules\n",
    "3. **Documentation:** Serve as living documentation of data expectations\n",
    "4. **Trust:** Build confidence in data-driven decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Implementing Data Contracts in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Example: Create a table with data contracts\n",
    "DROP TABLE IF EXISTS validated_readings;\n",
    "\n",
    "CREATE TABLE validated_readings (\n",
    "    -- Primary Key Contract: Unique identifier required\n",
    "    reading_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    \n",
    "    -- Not Null Contract: These fields are required\n",
    "    reading_datetime DATETIME NOT NULL,\n",
    "    \n",
    "    -- Range Contract: Temperature must be realistic (-50 to 60 Celsius)\n",
    "    temperature DECIMAL(5,2) CHECK (temperature >= -50 AND temperature <= 60),\n",
    "    \n",
    "    -- Range Contract: Humidity must be 0-100%\n",
    "    rel_humidity DECIMAL(5,2) CHECK (rel_humidity >= 0 AND rel_humidity <= 100),\n",
    "    \n",
    "    -- Range Contract: CO must be non-negative\n",
    "    co_gt DECIMAL(10,4) CHECK (co_gt >= 0),\n",
    "    \n",
    "    -- Quality flag for data lineage\n",
    "    quality_flag ENUM('VALIDATED', 'ESTIMATED', 'MISSING') DEFAULT 'VALIDATED',\n",
    "    \n",
    "    -- Audit fields\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    -- Index for query performance\n",
    "    INDEX idx_datetime (reading_datetime)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Test the data contract: This should succeed\n",
    "INSERT INTO validated_readings (reading_datetime, temperature, rel_humidity, co_gt)\n",
    "VALUES ('2024-01-01 10:00:00', 25.5, 65.0, 1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Verify the insert\n",
    "SELECT * FROM validated_readings;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Validating Existing Data Against Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Data Contract Validation Report\n",
    "SELECT \n",
    "    'Temperature Range Check' AS contract_name,\n",
    "    COUNT(*) AS total_records,\n",
    "    SUM(CASE WHEN temperature < -50 OR temperature > 60 THEN 1 ELSE 0 END) AS violations,\n",
    "    ROUND(SUM(CASE WHEN temperature < -50 OR temperature > 60 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS violation_pct\n",
    "FROM air_quality_readings\n",
    "WHERE temperature IS NOT NULL\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'Humidity Range Check',\n",
    "    COUNT(*),\n",
    "    SUM(CASE WHEN rel_humidity < 0 OR rel_humidity > 100 THEN 1 ELSE 0 END),\n",
    "    ROUND(SUM(CASE WHEN rel_humidity < 0 OR rel_humidity > 100 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2)\n",
    "FROM air_quality_readings\n",
    "WHERE rel_humidity IS NOT NULL\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'CO Non-Negative Check',\n",
    "    COUNT(*),\n",
    "    SUM(CASE WHEN co_gt < 0 THEN 1 ELSE 0 END),\n",
    "    ROUND(SUM(CASE WHEN co_gt < 0 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2)\n",
    "FROM air_quality_readings\n",
    "WHERE co_gt IS NOT NULL\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'Required DateTime Check',\n",
    "    COUNT(*),\n",
    "    SUM(CASE WHEN reading_datetime IS NULL THEN 1 ELSE 0 END),\n",
    "    ROUND(SUM(CASE WHEN reading_datetime IS NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2)\n",
    "FROM air_quality_readings;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Practice Exercises\n",
    "\n",
    "Try these exercises on your own before looking at the solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: JOIN Practice\n",
    "Write a query to find the top 5 days with the highest benzene levels, and classify each into a pollution category using the pollution_thresholds table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: CTE Practice\n",
    "Using CTEs, find the percentage of hours each day that had \"Unhealthy\" CO levels (above 4.0 mg/m3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Window Function Practice\n",
    "For each month, calculate the daily CO reading's percentile rank within that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Combined Challenge\n",
    "Find hours where the CO level was more than 2 standard deviations above the daily average for that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Solution 1: JOIN to classify benzene levels\n",
    "SELECT \n",
    "    d.reading_date,\n",
    "    d.max_benzene,\n",
    "    p.level_name,\n",
    "    p.health_advisory\n",
    "FROM daily_summary d\n",
    "INNER JOIN pollution_thresholds p \n",
    "    ON p.pollutant = 'Benzene'\n",
    "    AND d.max_benzene >= p.min_value \n",
    "    AND d.max_benzene < p.max_value\n",
    "WHERE d.max_benzene IS NOT NULL\n",
    "ORDER BY d.max_benzene DESC\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Solution 2: CTE for unhealthy hours percentage\n",
    "WITH daily_health AS (\n",
    "    SELECT \n",
    "        reading_date,\n",
    "        COUNT(*) AS total_hours,\n",
    "        SUM(CASE WHEN co_gt > 4.0 THEN 1 ELSE 0 END) AS unhealthy_hours\n",
    "    FROM air_quality_readings\n",
    "    WHERE co_gt IS NOT NULL\n",
    "    GROUP BY reading_date\n",
    ")\n",
    "SELECT \n",
    "    reading_date,\n",
    "    total_hours,\n",
    "    unhealthy_hours,\n",
    "    ROUND(unhealthy_hours * 100.0 / total_hours, 2) AS unhealthy_pct\n",
    "FROM daily_health\n",
    "WHERE unhealthy_hours > 0\n",
    "ORDER BY unhealthy_pct DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Solution 3: Percentile rank by month\n",
    "SELECT \n",
    "    reading_date,\n",
    "    month,\n",
    "    avg_co,\n",
    "    ROUND(PERCENT_RANK() OVER (PARTITION BY month ORDER BY avg_co) * 100, 2) AS percentile_rank\n",
    "FROM daily_summary\n",
    "WHERE avg_co IS NOT NULL\n",
    "ORDER BY month, percentile_rank DESC\n",
    "LIMIT 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Solution 4: Hours more than 2 std dev above daily average\n",
    "WITH daily_stats AS (\n",
    "    SELECT \n",
    "        reading_date,\n",
    "        AVG(co_gt) AS daily_avg,\n",
    "        STDDEV(co_gt) AS daily_std\n",
    "    FROM air_quality_readings\n",
    "    WHERE co_gt IS NOT NULL\n",
    "    GROUP BY reading_date\n",
    ")\n",
    "SELECT \n",
    "    r.reading_datetime,\n",
    "    r.co_gt,\n",
    "    ROUND(s.daily_avg, 4) AS daily_avg,\n",
    "    ROUND(s.daily_std, 4) AS daily_std,\n",
    "    ROUND((r.co_gt - s.daily_avg) / s.daily_std, 2) AS z_score\n",
    "FROM air_quality_readings r\n",
    "JOIN daily_stats s ON r.reading_date = s.reading_date\n",
    "WHERE r.co_gt IS NOT NULL\n",
    "    AND s.daily_std > 0\n",
    "    AND (r.co_gt - s.daily_avg) / s.daily_std > 2\n",
    "ORDER BY z_score DESC\n",
    "LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Summary\n",
    "\n",
    "### What We Covered Today\n",
    "\n",
    "1. **Loading CSV Data into MySQL**\n",
    "   - Reading CSV with pandas (handling European decimal format)\n",
    "   - Cleaning and transforming data\n",
    "   - Bulk loading with to_sql()\n",
    "\n",
    "2. **SQL JOINs**\n",
    "   - INNER JOIN: Only matching rows\n",
    "   - LEFT JOIN: All from left, matches from right\n",
    "   - RIGHT JOIN: All from right, matches from left\n",
    "   - CROSS JOIN: Cartesian product\n",
    "   - SELF JOIN: Comparing rows within same table\n",
    "\n",
    "3. **Common Table Expressions (CTEs)**\n",
    "   - Single CTEs for readability\n",
    "   - Multiple CTEs for step-by-step analysis\n",
    "   - Chaining CTEs together\n",
    "\n",
    "4. **Window Functions**\n",
    "   - ROW_NUMBER, RANK, DENSE_RANK for ranking\n",
    "   - LAG/LEAD for comparing to previous/next rows\n",
    "   - Running totals and moving averages\n",
    "\n",
    "5. **Data Contracts**\n",
    "   - Schema, nullability, range, and referential contracts\n",
    "   - Implementing constraints in SQL\n",
    "   - Validating existing data\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | When to Use |\n",
    "|---------|-------------|\n",
    "| INNER JOIN | Need only matching records from both tables |\n",
    "| LEFT JOIN | Need all records from main table + optional data |\n",
    "| CTE | Complex queries that benefit from step-by-step logic |\n",
    "| Window Functions | Need calculations across related rows without grouping |\n",
    "| Data Contracts | Ensuring data quality and consistency |\n",
    "\n",
    "### Next Class Preview\n",
    "\n",
    "In the next lecture, we will cover:\n",
    "- ETL Pipeline I: CSV/JSON data ingestion\n",
    "- Raw vs cleaned data layers\n",
    "- Data lineage and transformation tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. References\n",
    "\n",
    "### Official Documentation\n",
    "\n",
    "1. **MySQL 8.0 Reference Manual - JOIN Syntax**  \n",
    "   https://dev.mysql.com/doc/refman/8.0/en/join.html\n",
    "\n",
    "2. **MySQL 8.0 Reference Manual - WITH (Common Table Expressions)**  \n",
    "   https://dev.mysql.com/doc/refman/8.0/en/with.html\n",
    "\n",
    "3. **MySQL 8.0 Reference Manual - Window Functions**  \n",
    "   https://dev.mysql.com/doc/refman/8.0/en/window-functions.html\n",
    "\n",
    "4. **Pandas Documentation - to_sql()**  \n",
    "   https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html\n",
    "\n",
    "### Dataset\n",
    "\n",
    "5. **UCI Machine Learning Repository - Air Quality Dataset**  \n",
    "   https://archive.ics.uci.edu/ml/datasets/Air+Quality\n",
    "\n",
    "### Books\n",
    "\n",
    "6. Beaulieu, A. (2020). *Learning SQL: Generate, Manipulate, and Retrieve Data* (3rd ed.). O'Reilly Media.\n",
    "\n",
    "7. Molinaro, A., & Graaf, R. (2020). *SQL Cookbook* (2nd ed.). O'Reilly Media.\n",
    "\n",
    "### Online Resources\n",
    "\n",
    "8. **Mode SQL Tutorial - Window Functions**  \n",
    "   https://mode.com/sql-tutorial/sql-window-functions/\n",
    "\n",
    "9. **PostgreSQL Tutorial - CTEs**  \n",
    "   https://www.postgresqltutorial.com/postgresql-cte/\n",
    "\n",
    "10. **Data Engineering Weekly - Data Contracts**  \n",
    "    https://dataengineeringweekly.com/data-contracts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup (Optional)\n",
    "\n",
    "Run these commands when you are finished to clean up the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Drop tables (uncomment to run)\n",
    "-- DROP TABLE IF EXISTS validated_readings;\n",
    "-- DROP TABLE IF EXISTS air_quality_readings;\n",
    "-- DROP TABLE IF EXISTS daily_summary;\n",
    "-- DROP TABLE IF EXISTS monthly_summary;\n",
    "-- DROP TABLE IF EXISTS sensor_info;\n",
    "-- DROP TABLE IF EXISTS pollution_thresholds;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
