{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRE 521D: Data Analytics in Climate, Food and Environment\n",
    "## Lab 2: Building an ETL Pipeline\n",
    "\n",
    "**Program:** UBC Master of Food and Resource Economics  \n",
    "**Instructor:** Asif Ahmed Neloy\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color: #FFF3CD; border-left: 4px solid #E6A23C; padding: 15px; margin: 15px 0;\">\n",
    "    <h3 style=\"margin-top: 0; color: #856404;\">Submission Deadline</h3>\n",
    "    <p style=\"margin-bottom: 0; font-size: 1.2em;\"><strong>End of Day: Wednesday, January 14, 2026</strong></p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Lab Objectives\n",
    "\n",
    "In this lab, you will build an ETL (Extract, Transform, Load) pipeline for climate change data. You will:\n",
    "\n",
    "1. **Extract**: Load the raw CSV data safely and add metadata columns\n",
    "2. **Transform**: Clean column names and select relevant columns\n",
    "3. **Load**: Save both raw and cleaned layers with proper documentation\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The `climate_change_indicators.csv` file contains **surface temperature change** data from the FAO (Food and Agriculture Organization). It shows how much warmer or cooler each country was compared to the 1951-1980 baseline period.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Current time: 2026-01-14 10:25:09\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Create directory structure for raw and cleaned layers\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "os.makedirs('data/cleaned', exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Raw Data First\n",
    "\n",
    "As covered in Lecture 3, **always inspect your data before loading it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0: ObjectId,Country,ISO2,ISO3,Indicator,Unit,Source,CTS_Code,CTS_Name,CTS_Full_Descriptor,F1961,F1962,F...\n",
      "Line 1: 1,\"Afghanistan, Islamic Rep. of\",AF,AFG,\"Temperature change with respect to a baseline climatology, ...\n",
      "Line 2: 2,Albania,AL,ALB,\"Temperature change with respect to a baseline climatology, corresponding to the pe...\n"
     ]
    }
   ],
   "source": [
    "# Look at the first few lines as raw text\n",
    "with open('climate_change_indicators.csv', 'r', encoding='utf-8-sig') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 3:\n",
    "            print(f\"Line {i}: {line[:100]}...\")\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 225 rows, 72 columns\n",
      "\n",
      "Column names:\n",
      "  0: ObjectId\n",
      "  1: Country\n",
      "  2: ISO2\n",
      "  3: ISO3\n",
      "  4: Indicator\n",
      "  5: Unit\n",
      "  6: Source\n",
      "  7: CTS_Code\n",
      "  8: CTS_Name\n",
      "  9: CTS_Full_Descriptor\n",
      "  10: F1961\n",
      "  11: F1962\n",
      "  12: F1963\n",
      "  13: F1964\n",
      "  14: F1965\n",
      "  15: F1966\n",
      "  16: F1967\n",
      "  17: F1968\n",
      "  18: F1969\n",
      "  19: F1970\n",
      "  20: F1971\n",
      "  21: F1972\n",
      "  22: F1973\n",
      "  23: F1974\n",
      "  24: F1975\n",
      "  25: F1976\n",
      "  26: F1977\n",
      "  27: F1978\n",
      "  28: F1979\n",
      "  29: F1980\n",
      "  30: F1981\n",
      "  31: F1982\n",
      "  32: F1983\n",
      "  33: F1984\n",
      "  34: F1985\n",
      "  35: F1986\n",
      "  36: F1987\n",
      "  37: F1988\n",
      "  38: F1989\n",
      "  39: F1990\n",
      "  40: F1991\n",
      "  41: F1992\n",
      "  42: F1993\n",
      "  43: F1994\n",
      "  44: F1995\n",
      "  45: F1996\n",
      "  46: F1997\n",
      "  47: F1998\n",
      "  48: F1999\n",
      "  49: F2000\n",
      "  50: F2001\n",
      "  51: F2002\n",
      "  52: F2003\n",
      "  53: F2004\n",
      "  54: F2005\n",
      "  55: F2006\n",
      "  56: F2007\n",
      "  57: F2008\n",
      "  58: F2009\n",
      "  59: F2010\n",
      "  60: F2011\n",
      "  61: F2012\n",
      "  62: F2013\n",
      "  63: F2014\n",
      "  64: F2015\n",
      "  65: F2016\n",
      "  66: F2017\n",
      "  67: F2018\n",
      "  68: F2019\n",
      "  69: F2020\n",
      "  70: F2021\n",
      "  71: F2022\n"
     ]
    }
   ],
   "source": [
    "# Load and explore the data\n",
    "df = pd.read_csv('climate_change_indicators.csv', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i}: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO2</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Source</th>\n",
       "      <th>...</th>\n",
       "      <th>F2016</th>\n",
       "      <th>F2017</th>\n",
       "      <th>F2018</th>\n",
       "      <th>F2019</th>\n",
       "      <th>F2020</th>\n",
       "      <th>F2021</th>\n",
       "      <th>F2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan, Islamic Rep. of</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Temperature change with respect to a baseline ...</td>\n",
       "      <td>Degree Celsius</td>\n",
       "      <td>Food and Agriculture Organization of the Unite...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1.544</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.498</td>\n",
       "      <td>1.327</td>\n",
       "      <td>2.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Temperature change with respect to a baseline ...</td>\n",
       "      <td>Degree Celsius</td>\n",
       "      <td>Food and Agriculture Organization of the Unite...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.121</td>\n",
       "      <td>2.028</td>\n",
       "      <td>1.675</td>\n",
       "      <td>1.498</td>\n",
       "      <td>1.536</td>\n",
       "      <td>1.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Temperature change with respect to a baseline ...</td>\n",
       "      <td>Degree Celsius</td>\n",
       "      <td>Food and Agriculture Organization of the Unite...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757</td>\n",
       "      <td>1.512</td>\n",
       "      <td>1.210</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.926</td>\n",
       "      <td>2.330</td>\n",
       "      <td>1.688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ObjectId                       Country ISO2 ISO3  \\\n",
       "0         1  Afghanistan, Islamic Rep. of   AF  AFG   \n",
       "1         2                       Albania   AL  ALB   \n",
       "2         3                       Algeria   DZ  DZA   \n",
       "\n",
       "                                           Indicator            Unit  \\\n",
       "0  Temperature change with respect to a baseline ...  Degree Celsius   \n",
       "1  Temperature change with respect to a baseline ...  Degree Celsius   \n",
       "2  Temperature change with respect to a baseline ...  Degree Celsius   \n",
       "\n",
       "                                              Source  ...  F2016  F2017  \\\n",
       "0  Food and Agriculture Organization of the Unite...  ...  1.555  1.540   \n",
       "1  Food and Agriculture Organization of the Unite...  ...  1.464  1.121   \n",
       "2  Food and Agriculture Organization of the Unite...  ...  1.757  1.512   \n",
       "\n",
       "   F2018  F2019  F2020  F2021  F2022  \n",
       "0  1.544  0.910  0.498  1.327  2.012  \n",
       "1  2.028  1.675  1.498  1.536  1.518  \n",
       "2  1.210  1.115  1.926  2.330  1.688  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View sample of the data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Question 1: Extract Phase - Create Raw Layer \n",
    "## Task: Extract Data and Add Metadata Columns\n",
    "\n",
    "As discussed in Lecture 3, the **raw layer** should:\n",
    "1. Contain the exact source data (no transformations)\n",
    "2. Add metadata columns to track data lineage\n",
    "\n",
    "**Complete the function below** to add these metadata columns:\n",
    "- `_source_file`: The name of the source file (use `os.path.basename()`)\n",
    "- `_extracted_at`: The timestamp when extracted (use `datetime.now().isoformat()`)\n",
    "- `_row_num`: Row numbers starting from 1 (use `range(1, len(df) + 1)`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_to_raw(filepath):\n",
    "    \"\"\"\n",
    "    Extract data from source file and add metadata columns.\n",
    "    This creates the RAW LAYER of our ETL pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to the source CSV file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with source data plus metadata columns\n",
    "    \"\"\"\n",
    "    # Read the CSV file (keeping data as-is)\n",
    "    df = pd.read_csv(filepath, encoding='utf-8-sig')\n",
    "    \n",
    "    # ============================================\n",
    "    # YOUR CODE HERE: Add the 3 metadata columns\n",
    "    # ============================================\n",
    "    \n",
    "    # 1. Add _source_file column\n",
    "    \n",
    "    \n",
    "    # 2. Add _extracted_at column\n",
    "    \n",
    "    \n",
    "    # 3. Add _row_num column\n",
    "    \n",
    "    \n",
    "    # ============================================\n",
    "    \n",
    "    print(f\"Extracted {len(df)} rows from {filepath}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function\n",
    "df_raw = extract_to_raw('climate_change_indicators.csv')\n",
    "\n",
    "# Verify metadata columns were added\n",
    "print(\"\\nChecking metadata columns:\")\n",
    "print(f\"  _source_file exists: {'_source_file' in df_raw.columns}\")\n",
    "print(f\"  _extracted_at exists: {'_extracted_at' in df_raw.columns}\")\n",
    "print(f\"  _row_num exists: {'_row_num' in df_raw.columns}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample with metadata columns:\")\n",
    "df_raw[['Country', 'ISO3', '_source_file', '_extracted_at', '_row_num']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw layer\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "raw_filepath = f'data/raw/climate_indicators_raw_{timestamp}.csv'\n",
    "df_raw.to_csv(raw_filepath, index=False)\n",
    "print(f\"Raw layer saved to: {raw_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Question 2: Transform Phase - Create Cleaned Layer\n",
    "\n",
    "## Task: Clean and Simplify the Data\n",
    "\n",
    "The raw data has many columns we don't need. For the **cleaned layer**, we will:\n",
    "1. Select only the useful columns\n",
    "2. Rename columns to be more database-friendly (lowercase, underscores)\n",
    "3. Add a timestamp for when the data was cleaned\n",
    "\n",
    "**Complete the function below** to:\n",
    "1. Select these columns: `Country`, `ISO3`, `F2000`, `F2010`, `F2020`, `F2022`\n",
    "2. Rename them to: `country`, `iso3`, `temp_2000`, `temp_2010`, `temp_2020`, `temp_2022`\n",
    "3. Add a `_cleaned_at` column with the current timestamp\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_cleaned(df_raw):\n",
    "    \"\"\"\n",
    "    Transform raw data to cleaned layer.\n",
    "    Selects relevant columns and standardizes names.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_raw : pd.DataFrame\n",
    "        Raw data from extract phase\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with cleaned data\n",
    "    \"\"\"\n",
    "    # ============================================\n",
    "    # YOUR CODE HERE\n",
    "    # ============================================\n",
    "    \n",
    "    # Step 1: Select only the columns we need\n",
    "    # Columns to keep: 'Country', 'ISO3', 'F2000', 'F2010', 'F2020', 'F2022'\n",
    "    columns_to_keep = ['Country', 'ISO3', 'F2000', 'F2010', 'F2020', 'F2022']\n",
    "    df = df_raw[columns_to_keep].copy()\n",
    "    \n",
    "    # Step 2: Rename columns to be database-friendly\n",
    "    # Use df.rename(columns={old_name: new_name, ...})\n",
    "    # New names: 'country', 'iso3', 'temp_2000', 'temp_2010', 'temp_2020', 'temp_2022'\n",
    "    \n",
    "    df = df.rename(columns={\n",
    "        # YOUR CODE: fill in the mapping\n",
    "        \n",
    "    })\n",
    "    \n",
    "    # Step 3: Add _cleaned_at timestamp column\n",
    "    \n",
    "    \n",
    "    # ============================================\n",
    "    \n",
    "    print(f\"Cleaned data: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function\n",
    "df_clean = transform_to_cleaned(df_raw)\n",
    "\n",
    "# Verify the transformation\n",
    "print(\"\\nCleaned column names:\")\n",
    "print(df_clean.columns.tolist())\n",
    "\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned layer\n",
    "cleaned_filepath = f'data/cleaned/climate_indicators_cleaned_{timestamp}.csv'\n",
    "df_clean.to_csv(cleaned_filepath, index=False)\n",
    "print(f\"Cleaned layer saved to: {cleaned_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Question 3: Data Lineage Documentation \n",
    "\n",
    "## Task: Document Your Pipeline\n",
    "\n",
    "As discussed in Lecture 3, **data lineage** tracks:\n",
    "- Where the data came from\n",
    "- What transformations were applied\n",
    "- When the pipeline was run\n",
    "\n",
    "**Fill in the transformations list** with at least 4 things your pipeline did.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# YOUR CODE HERE: List at least 4 transformations\n",
    "# ============================================\n",
    "\n",
    "transformations = [\n",
    "    # Example: \"Added metadata columns (_source_file, _extracted_at, _row_num)\"\n",
    "    # List what your pipeline did...\n",
    "    \n",
    "]\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lineage documentation\n",
    "lineage_doc = f\"\"\"\n",
    "# Data Lineage Documentation\n",
    "\n",
    "Generated: {datetime.now().isoformat()}\n",
    "\n",
    "## Source\n",
    "- File: climate_change_indicators.csv\n",
    "- Description: FAO Climate Change Indicators - Surface Temperature Change\n",
    "- Rows: {len(df_raw)}\n",
    "\n",
    "## Raw Layer\n",
    "- File: {raw_filepath}\n",
    "- Contains exact copy of source with metadata columns added\n",
    "\n",
    "## Cleaned Layer\n",
    "- File: {cleaned_filepath}\n",
    "- Columns: {df_clean.columns.tolist()}\n",
    "\n",
    "## Transformations Applied\n",
    "\"\"\"\n",
    "\n",
    "for i, t in enumerate(transformations, 1):\n",
    "    lineage_doc += f\"{i}. {t}\\n\"\n",
    "\n",
    "# Save and display\n",
    "with open('data/cleaned/README.md', 'w') as f:\n",
    "    f.write(lineage_doc)\n",
    "\n",
    "print(lineage_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Verify Your Work\n",
    "\n",
    "Run this cell to check that everything was created correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification\n",
    "print(\"=\" * 50)\n",
    "print(\"ETL Pipeline Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n[EXTRACT] Raw layer:\")\n",
    "print(f\"  - Rows: {len(df_raw)}\")\n",
    "print(f\"  - Has _source_file: {'_source_file' in df_raw.columns}\")\n",
    "print(f\"  - Has _extracted_at: {'_extracted_at' in df_raw.columns}\")\n",
    "print(f\"  - Has _row_num: {'_row_num' in df_raw.columns}\")\n",
    "\n",
    "print(f\"\\n[TRANSFORM] Cleaned layer:\")\n",
    "print(f\"  - Rows: {len(df_clean)}\")\n",
    "print(f\"  - Columns: {df_clean.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\n[LOAD] Files saved:\")\n",
    "print(f\"  - Raw: {raw_filepath}\")\n",
    "print(f\"  - Cleaned: {cleaned_filepath}\")\n",
    "print(f\"  - README: data/cleaned/README.md\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, make sure:\n",
    "\n",
    "- [ ] **Question 1**: `extract_to_raw()` adds all 3 metadata columns\n",
    "- [ ] **Question 2**: `transform_to_cleaned()` selects and renames columns correctly\n",
    "- [ ] **Question 3**: You listed at least 4 transformations\n",
    "- [ ] All files were saved to `data/raw/` and `data/cleaned/`\n",
    "\n",
    "### How to Submit\n",
    "\n",
    "1. Save this notebook\n",
    "2. Submit via Canvas (Lab 2 Submission) by **end of day Wednesday, January 14, 2026**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
